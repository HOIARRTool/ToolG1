# ==============================================================================
# IMPORT LIBRARIES
# ==============================================================================
import streamlit as st
import pandas as pd
from pathlib import Path
import base64
from datetime import datetime, date
from dateutil.relativedelta import relativedelta
import numpy as np
import re
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
import plotly.express as px
import plotly.graph_objects as go
try:
    import google.generativeai as genai
except ImportError:
    genai = None

# --- REMOVED: weasyprint import ---
# The try-except block for importing weasyprint has been removed as it's no longer needed.

# ==============================================================================
# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏•‡∏±‡∏Å ---
# ==============================================================================
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)
PERSISTED_DATA_PATH = DATA_DIR / "processed_incident_data.parquet"
ADMIN_PASSWORD = st.secrets.get("ADMIN_PASSWORD", "admin1234")

# ==============================================================================
# PAGE CONFIGURATION
# ==============================================================================
LOGO_URL = "https://raw.githubusercontent.com/HOIARRTool/hoiarr/refs/heads/main/logo1.png"
st.set_page_config(page_title="HOIA-RR", page_icon=LOGO_URL, layout="wide")
st.markdown("""
<style>
/* CSS to style the text area inside the chat input */
[data-testid="stChatInput"] textarea { min-height: 80px; height: 100px; resize: vertical; background-color: transparent; border: none; }
</style>
""", unsafe_allow_html=True)
st.markdown("""
<style>
@media print {
    div[data-testid="stHorizontalBlock"] { display: grid !important; grid-template-columns: repeat(5, 1fr) !important; gap: 1.2rem !important; }
    .stDataFrame, .stTable { break-inside: avoid; page-break-inside: avoid; }
    thead, tr, th, td { break-inside: avoid !important; page-break-inside: avoid !important; }
    h1, h2, h3, h4, h5 { page-break-after: avoid; }
}
.custom-header { font-size: 20px; font-weight: bold; margin-top: 0px !important; padding-top: 0px !important; }
div[data-testid="stHorizontalBlock"] > div div[data-testid="stMetric"] { border: 1px solid #ddd; padding: 0.75rem; border-radius: 0.5rem; height: 100%; display: flex; flex-direction: column; justify-content: center; }
div[data-testid="stHorizontalBlock"] > div:nth-child(1) div[data-testid="stMetric"] { background-color: #e6fffa; border-color: #b2f5ea; }
div[data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stMetric"] { background-color: #fff3e0; border-color: #ffe0b2; }
div[data-testid="stHorizontalBlock"] > div:nth-child(3) div[data-testid="stMetric"] { background-color: #fce4ec; border-color: #f8bbd0; }
div[data-testid="stHorizontalBlock"] > div:nth-child(4) div[data-testid="stMetric"] { background-color: #e3f2fd; border-color: #bbdefb; }
div[data-testid="stHorizontalBlock"] > div div[data-testid="stMetric"] [data-testid="stMetricLabel"] > div,
div[data-testid="stHorizontalBlock"] > div div[data-testid="stMetric"] [data-testid="stMetricValue"],
div[data-testid="stHorizontalBlock"] > div div[data-testid="stMetric"] [data-testid="stMetricDelta"] { color: #262730 !important; }
div[data-testid="stMetric"] [data-testid="stMetricLabel"] > div { font-size: 0.8rem !important; line-height: 1.2 !important; white-space: normal !important; overflow-wrap: break-word !important; word-break: break-word; display: block !important; }
div[data-testid="stMetric"] [data-testid="stMetricValue"] { font-size: 1.3rem !important; }
div[data-testid="stMetric"] [data-testid="stMetricDelta"] { font-size: 0.75rem !important; }
div[data-testid="stHorizontalBlock"] > div .stExpander { border: none !important; box-shadow: none !important; padding: 0 !important; margin-top: 0.5rem; }
div[data-testid="stHorizontalBlock"] > div .stExpander header { padding: 0.25rem 0.5rem !important; font-size: 0.75rem !important; border-radius: 0.25rem; }
div[data-testid="stHorizontalBlock"] > div .stExpander div[data-testid="stExpanderDetails"] { max-height: 200px; overflow-y: auto; }
.stDataFrame table td, .stDataFrame table th { color: black !important; font-size: 0.9rem !important; }
.stDataFrame table th { font-weight: bold !important; }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# ANALYSIS FUNCTIONS
# ==============================================================================
def load_data(uploaded_file):
    try:
        return pd.read_excel(uploaded_file, engine='openpyxl', keep_default_na=False)
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel: {e}")
        return pd.DataFrame()


@st.cache_data
def calculate_persistence_risk_score(_df: pd.DataFrame, total_months: int):
    risk_level_map_to_score = {"51": 21, "52": 22, "53": 23, "54": 24, "55": 25, "41": 16, "42": 17, "43": 18, "44": 19,
                               "45": 20, "31": 11, "32": 12, "33": 13, "34": 14, "35": 15, "21": 6, "22": 7, "23": 8,
                               "24": 9, "25": 10, "11": 1, "12": 2, "13": 3, "14": 4, "15": 5}
    if _df.empty or '‡∏£‡∏´‡∏±‡∏™' not in _df.columns or 'Risk Level' not in _df.columns: return pd.DataFrame()
    analysis_df = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Risk Level']].copy()
    analysis_df['Ordinal_Risk_Score'] = analysis_df['Risk Level'].astype(str).map(risk_level_map_to_score)
    analysis_df.dropna(subset=['Ordinal_Risk_Score'], inplace=True)
    if analysis_df.empty: return pd.DataFrame()
    persistence_metrics = analysis_df.groupby('‡∏£‡∏´‡∏±‡∏™').agg(
        Average_Ordinal_Risk_Score=('Ordinal_Risk_Score', 'mean'),
        Total_Occurrences=('‡∏£‡∏´‡∏±‡∏™', 'size')
    ).reset_index()
    total_months = max(1, total_months)
    persistence_metrics['Incident_Rate_Per_Month'] = persistence_metrics['Total_Occurrences'] / total_months
    max_rate = max(1, persistence_metrics['Incident_Rate_Per_Month'].max())
    persistence_metrics['Frequency_Score'] = persistence_metrics['Incident_Rate_Per_Month'] / max_rate
    persistence_metrics['Avg_Severity_Score'] = persistence_metrics['Average_Ordinal_Risk_Score'] / 25.0
    persistence_metrics['Persistence_Risk_Score'] = persistence_metrics['Frequency_Score'] + persistence_metrics[
        'Avg_Severity_Score']
    incident_names = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
    final_df = pd.merge(persistence_metrics, incident_names, on='‡∏£‡∏´‡∏±‡∏™', how='left')
    return final_df.sort_values(by='Persistence_Risk_Score', ascending=False)


@st.cache_data
def calculate_frequency_trend_poisson(_df: pd.DataFrame):
    if _df.empty or '‡∏£‡∏´‡∏±‡∏™' not in _df.columns or 'Occurrence Date' not in _df.columns: return pd.DataFrame()
    analysis_df = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Occurrence Date']].copy()
    analysis_df.dropna(subset=['Occurrence Date'], inplace=True)
    if analysis_df.empty: return pd.DataFrame()
    analysis_df['YearMonth'] = pd.to_datetime(analysis_df['Occurrence Date']).dt.to_period('M')
    full_date_range = pd.period_range(start=analysis_df['YearMonth'].min(), end=analysis_df['YearMonth'].max(),
                                      freq='M')
    results = []
    for code in analysis_df['‡∏£‡∏´‡∏±‡∏™'].unique():
        incident_subset = analysis_df[analysis_df['‡∏£‡∏´‡∏±‡∏™'] == code]
        if len(incident_subset) < 3 or len(incident_subset.groupby('YearMonth')) < 2: continue
        monthly_counts = incident_subset.groupby('YearMonth').size().reindex(full_date_range, fill_value=0)
        y = monthly_counts.values
        X = sm.add_constant(np.arange(len(monthly_counts)))
        try:
            model = sm.Poisson(y, X).fit(disp=0)
            results.append({
                '‡∏£‡∏´‡∏±‡∏™': code, 'Poisson_Trend_Slope': model.params[1],
                'Total_Occurrences': y.sum(), 'Months_Observed': len(y)
            })
        except Exception:
            continue
    if not results: return pd.DataFrame()
    final_df = pd.DataFrame(results)
    incident_names = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
    final_df = pd.merge(final_df, incident_names, on='‡∏£‡∏´‡∏±‡∏™', how='left')
    return final_df.sort_values(by='Poisson_Trend_Slope', ascending=False)


def create_poisson_trend_plot(df, selected_code_for_plot, display_df=None, show_ci=True):
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÅ‡∏Å‡∏ô x)
    full_date_range_for_plot = pd.period_range(
        start=pd.to_datetime(df['Occurrence Date']).dt.to_period('M').min(),
        end=pd.to_datetime(df['Occurrence Date']).dt.to_period('M').max(),
        freq='M'
    )

    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    subset = df[df['‡∏£‡∏´‡∏±‡∏™'] == selected_code_for_plot].copy()
    subset['YearMonth'] = pd.to_datetime(subset['Occurrence Date']).dt.to_period('M')
    counts = subset.groupby('YearMonth').size().reindex(full_date_range_for_plot, fill_value=0)

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Poisson: y = counts, X = [const, time]
    y = counts.values.astype(float)
    t = np.arange(len(counts), dtype=float)
    X = sm.add_constant(t)

    # fit Poisson (log link): mu_t = exp(beta0 + beta1 * t)
    beta0 = beta1 = None
    mu_hat = None
    mu_lo = mu_hi = None

    if len(y) >= 2 and y.sum() > 0:
        try:
            model = sm.Poisson(y, X).fit(disp=0)
            beta0, beta1 = model.params

            # ‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
            eta = beta0 + beta1 * t                      # linear predictor
            mu_hat = np.exp(eta)                      # expected counts

            if show_ci:
                # 95% CI ‡∏ö‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡∏•‡∏≠‡∏Å -> ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡∏ô‡∏±‡∏ö
                cov = model.cov_params()
                design = np.column_stack([np.ones_like(t), t])
                se_eta = np.sqrt(np.einsum('ij,jk,ik->i', design, cov, design))
                eta_lo = eta - 1.96 * se_eta
                eta_hi = eta + 1.96 * se_eta
                mu_lo = np.exp(eta_lo)
                mu_hi = np.exp(eta_hi)
        except Exception as e:
            st.warning(f"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° Poisson ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü
    fig_plot = go.Figure()

    # ‡πÅ‡∏ó‡πà‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    fig_plot.add_trace(go.Bar(
        x=counts.index.strftime('%Y-%m'),
        y=y,
        name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á',
        marker=dict(color='#AED6F1', cornerradius=8)
    ))

    # ‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏à‡∏≤‡∏Å Poisson + ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if mu_hat is not None:
        fig_plot.add_trace(go.Scatter(
            x=counts.index.strftime('%Y-%m'),
            y=mu_hat,
            mode='lines',
            name='‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡∏≤‡∏î‡∏´‡∏°‡∏≤‡∏¢ (Poisson)',
            line=dict(width=2)
        ))

        if show_ci and (mu_lo is not None) and (mu_hi is not None):
            # ‡∏ß‡∏≤‡∏î band 95% CI (‡∏ö‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß fill='tonexty')
            fig_plot.add_trace(go.Scatter(
                x=counts.index.strftime('%Y-%m'),
                y=mu_hi,
                mode='lines',
                line=dict(width=0),
                showlegend=False,
                hoverinfo='skip'
            ))
            fig_plot.add_trace(go.Scatter(
                x=counts.index.strftime('%Y-%m'),
                y=mu_lo,
                mode='lines',
                fill='tonexty',
                name='95% CI',
                line=dict(width=0),
                fillcolor='rgba(0,0,0,0.08)'
            ))

    fig_plot.update_layout(
        title=f'‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå: {selected_code_for_plot}',
        xaxis_title='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ',
        yaxis_title='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î',
        barmode='overlay',
        legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.7)')
    )

    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö: ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å Poisson (‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ) ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á display_df
    if beta1 is not None:
        factor = float(np.exp(beta1))
        annot_text = (f"<b>Poisson slope: {beta1:.4f}</b><br>"
                      f"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á: x{factor:.2f} ‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
    else:
        annot_text = "<b>Poisson slope: N/A</b><br>‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á: N/A"

    fig_plot.add_annotation(
        x=0.5, y=0.98,
        xref="paper", yref="paper",
        text=annot_text,
        showarrow=False,
        font=dict(size=12, color="black"),
        align="center",
        bordercolor="black",
        borderwidth=1,
        borderpad=4,
        bgcolor="rgba(255, 255, 224, 0.7)"
    )
    return fig_plot


def create_goal_summary_table(data_df_goal, goal_category_name_param,
                              e_up_non_numeric_levels_param, e_up_numeric_levels_param=None,
                              is_org_safety_table=False):
    goal_category_name_param = str(goal_category_name_param).strip()
    if '‡∏´‡∏°‡∏ß‡∏î' not in data_df_goal.columns:
        return pd.DataFrame()
    df_filtered_by_goal_cat = data_df_goal[
        data_df_goal['‡∏´‡∏°‡∏ß‡∏î'].astype(str).str.strip() == goal_category_name_param].copy()
    if df_filtered_by_goal_cat.empty: return pd.DataFrame()
    if 'Incident Type' not in df_filtered_by_goal_cat.columns or 'Impact' not in df_filtered_by_goal_cat.columns: return pd.DataFrame()
    try:
        pvt_table_goal = pd.crosstab(df_filtered_by_goal_cat['Incident Type'],
                                     df_filtered_by_goal_cat['Impact'].astype(str).str.strip(), margins=True,
                                     margins_name='‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î')
    except Exception:
        return pd.DataFrame()
    if '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î' in pvt_table_goal.index: pvt_table_goal = pvt_table_goal.drop(index='‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î')
    if pvt_table_goal.empty: return pd.DataFrame()
    if '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î' not in pvt_table_goal.columns: pvt_table_goal['‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] = pvt_table_goal.sum(axis=1)
    all_impact_columns_goal = [str(col).strip() for col in pvt_table_goal.columns if col != '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î']
    e_up_non_numeric_levels_param_stripped = [str(level).strip() for level in e_up_non_numeric_levels_param]
    e_up_numeric_levels_param_stripped = [str(level).strip() for level in
                                          e_up_numeric_levels_param] if e_up_numeric_levels_param else []
    e_up_columns_goal = [col for col in all_impact_columns_goal if
                         col not in e_up_non_numeric_levels_param_stripped and (
                                 not e_up_numeric_levels_param_stripped or col not in e_up_numeric_levels_param_stripped)]
    report_data_goal = []
    for incident_type_goal, row_data_goal in pvt_table_goal.iterrows():
        total_e_up_count_goal = sum(row_data_goal[col] for col in e_up_columns_goal if
                                    col in row_data_goal.index and pd.notna(row_data_goal[col]))
        total_all_impacts_goal = row_data_goal['‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] if '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î' in row_data_goal and pd.notna(
            row_data_goal['‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î']) else 0
        percent_e_up_goal = (total_e_up_count_goal / total_all_impacts_goal * 100) if total_all_impacts_goal > 0 else 0
        report_data_goal.append(
            {'Incident Type': incident_type_goal, '‡∏£‡∏ß‡∏° E-up': total_e_up_count_goal, '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up': percent_e_up_goal})
    report_df_goal = pd.DataFrame(report_data_goal)
    if report_df_goal.empty:
        merged_report_table_goal = pvt_table_goal.reset_index()
        merged_report_table_goal['‡∏£‡∏ß‡∏° E-up'] = 0
        merged_report_table_goal['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = 0.0
    else:
        merged_report_table_goal = pd.merge(pvt_table_goal.reset_index(), report_df_goal, on='Incident Type',
                                            how='outer')
    if '‡∏£‡∏ß‡∏° E-up' not in merged_report_table_goal.columns:
        merged_report_table_goal['‡∏£‡∏ß‡∏° E-up'] = 0
    else:
        merged_report_table_goal['‡∏£‡∏ß‡∏° E-up'].fillna(0, inplace=True)
    if '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up' not in merged_report_table_goal.columns:
        merged_report_table_goal['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = 0.0
    else:
        merged_report_table_goal['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'].fillna(0.0, inplace=True)
    cols_to_drop_from_display_goal = [col for col in e_up_non_numeric_levels_param_stripped if
                                      col in merged_report_table_goal.columns]
    if e_up_numeric_levels_param_stripped: cols_to_drop_from_display_goal.extend(
        [col for col in e_up_numeric_levels_param_stripped if col in merged_report_table_goal.columns])
    merged_report_table_goal = merged_report_table_goal.drop(columns=cols_to_drop_from_display_goal, errors='ignore')
    total_col_original_name, e_up_col_name, percent_e_up_col_name = '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î', '‡∏£‡∏ß‡∏° E-up', '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'
    if is_org_safety_table:
        total_col_display_name, e_up_col_display_name, percent_e_up_display_name = '‡∏£‡∏ß‡∏° 1-5', '‡∏£‡∏ß‡∏° 3-5', '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ 3-5'
        merged_report_table_goal.rename(
            columns={total_col_original_name: total_col_display_name, e_up_col_name: e_up_col_display_name,
                     percent_e_up_col_name: percent_e_up_display_name}, inplace=True, errors='ignore')
    else:
        total_col_display_name, e_up_col_display_name, percent_e_up_display_name = '‡∏£‡∏ß‡∏° A-I', e_up_col_name, percent_e_up_col_name
        merged_report_table_goal.rename(columns={total_col_original_name: total_col_display_name}, inplace=True,
                                        errors='ignore')
    merged_report_table_goal['Incident Type Name'] = merged_report_table_goal['Incident Type'].map(type_name).fillna(
        merged_report_table_goal['Incident Type'])
    final_columns_goal_order = ['Incident Type Name'] + [col for col in e_up_columns_goal if
                                                         col in merged_report_table_goal.columns] + [
                                   e_up_col_display_name, total_col_display_name, percent_e_up_display_name]
    final_columns_present_goal = [col for col in final_columns_goal_order if col in merged_report_table_goal.columns]
    merged_report_table_goal = merged_report_table_goal[final_columns_present_goal]
    if percent_e_up_display_name in merged_report_table_goal.columns and pd.api.types.is_numeric_dtype(
            merged_report_table_goal[percent_e_up_display_name]):
        try:
            merged_report_table_goal[percent_e_up_display_name] = merged_report_table_goal[
                percent_e_up_display_name].astype(float).map('{:.2f}%'.format)
        except ValueError:
            pass
    return merged_report_table_goal.set_index('Incident Type Name')


def create_severity_table(input_df, row_column_name, table_title, specific_row_order=None):
    if not isinstance(input_df,
                      pd.DataFrame) or input_df.empty or row_column_name not in input_df.columns or 'Impact Level' not in input_df.columns: return None
    temp_df = input_df.copy()
    temp_df['Impact Level'] = temp_df['Impact Level'].astype(str).str.strip().replace('N/A', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
    if temp_df[row_column_name].dropna().empty: return None
    try:
        severity_crosstab = pd.crosstab(temp_df[row_column_name].astype(str).str.strip(), temp_df['Impact Level'])
    except Exception:
        return None
    impact_level_map_cols = {'1': 'A-B (1)', '2': 'C-D (2)', '3': 'E-F (3)', '4': 'G-H (4)', '5': 'I (5)',
                             '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ LV'}
    desired_cols_ordered_keys = ['1', '2', '3', '4', '5', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏']
    for col_key in desired_cols_ordered_keys:
        if col_key not in severity_crosstab.columns: severity_crosstab[col_key] = 0
    present_ordered_keys = [key for key in desired_cols_ordered_keys if key in severity_crosstab.columns]
    if not present_ordered_keys: return None
    severity_crosstab = severity_crosstab[present_ordered_keys].rename(columns=impact_level_map_cols)
    final_display_cols_renamed = [impact_level_map_cols[key] for key in present_ordered_keys if
                                  key in impact_level_map_cols]
    if not final_display_cols_renamed: return None
    severity_crosstab['‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö'] = severity_crosstab[
        [col for col in final_display_cols_renamed if col in severity_crosstab.columns]].sum(axis=1)
    if specific_row_order:
        severity_crosstab = severity_crosstab.reindex([str(i) for i in specific_row_order]).fillna(0).astype(int)
    else:
        severity_crosstab = severity_crosstab[severity_crosstab['‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö'] > 0]
    if severity_crosstab.empty: return None
    st.markdown(f"##### {table_title}")
    display_column_order_from_map = [impact_level_map_cols.get(key) for key in desired_cols_ordered_keys]
    display_column_order_present = [col for col in display_column_order_from_map if
                                    col in severity_crosstab.columns] + (
                                       ['‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö'] if '‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö' in severity_crosstab.columns else [])
    st.dataframe(
        severity_crosstab[[col for col in display_column_order_present if col in severity_crosstab.columns]].astype(
            int), use_container_width=True)
    return severity_crosstab


def create_psg9_summary_table(input_df):
    if not isinstance(input_df,
                      pd.DataFrame) or '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' not in input_df.columns or 'Impact' not in input_df.columns: return None
    psg9_placeholders = ["‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô PSG9code.xlsx)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î/‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß - rename)", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß - no col)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)"]
    df_filtered = input_df[
        ~input_df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].isin(psg9_placeholders) & input_df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].notna()].copy()
    if df_filtered.empty: return pd.DataFrame()
    try:
        summary_table = pd.crosstab(df_filtered['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'], df_filtered['Impact'], margins=True,
                                    margins_name='‡∏£‡∏ß‡∏° A-I')
    except Exception:
        return pd.DataFrame()
    if '‡∏£‡∏ß‡∏° A-I' in summary_table.index: summary_table = summary_table.drop(index='‡∏£‡∏ß‡∏° A-I')
    if summary_table.empty: return pd.DataFrame()
    all_impacts, e_up_impacts = list('ABCDEFGHI'), list('EFGHI')
    for impact_col in all_impacts:
        if impact_col not in summary_table.columns: summary_table[impact_col] = 0
    if '‡∏£‡∏ß‡∏° A-I' not in summary_table.columns: summary_table['‡∏£‡∏ß‡∏° A-I'] = summary_table[
        [col for col in all_impacts if col in summary_table.columns]].sum(axis=1)
    summary_table['‡∏£‡∏ß‡∏° E-up'] = summary_table[[col for col in e_up_impacts if col in summary_table.columns]].sum(axis=1)
    summary_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = (summary_table['‡∏£‡∏ß‡∏° E-up'] / summary_table['‡∏£‡∏ß‡∏° A-I'] * 100).fillna(0)
    psg_order = [PSG9_label_dict[i] for i in sorted(PSG9_label_dict.keys())]
    summary_table = summary_table.reindex(psg_order).fillna(0)
    display_cols_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', '‡∏£‡∏ß‡∏° E-up', '‡∏£‡∏ß‡∏° A-I', '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up']
    final_table = summary_table[[col for col in display_cols_order if col in summary_table.columns]].copy()
    for col in final_table.columns:
        if col != '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up': final_table[col] = final_table[col].astype(int)
    final_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = final_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'].map('{:.2f}%'.format)
    return final_table


def get_text_color_for_bg(hex_color):
    try:
        hex_color = hex_color.lstrip('#')
        if len(hex_color) != 6: return '#000000'
        rgb = tuple(int(hex_color[i:i + 2], 16) for i in (0, 2, 4))
        luminance = (0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]) / 255
        return '#FFFFFF' if luminance < 0.5 else '#000000'
    except ValueError:
        return '#000000'


def prioritize_incidents_nb_logit_v2(_df: pd.DataFrame,
                                     horizon: int = 3,
                                     min_months: int = 4,
                                     min_total: int = 5,
                                     w_expected_severe: float = 0.7,
                                     w_freq_growth: float = 0.2,
                                     w_sev_growth: float = 0.1,
                                     alpha_floor: float = 1e-8):
    """
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Priority ‡πÅ‡∏ö‡∏ö NB+Logit ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏™‡∏Å‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏° DataFrame (‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å fillna ‡∏ö‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡∏≤‡∏£‡πå)
    """
    req = ['‡∏£‡∏´‡∏±‡∏™', 'Occurrence Date', 'Impact Level']
    if any(c not in _df.columns for c in req):
        return pd.DataFrame()

    d = _df.copy()
    d = d[pd.to_datetime(d['Occurrence Date'], errors='coerce').notna()]
    if d.empty:
        return pd.DataFrame()
    d['YearMonth'] = pd.to_datetime(d['Occurrence Date']).dt.to_period('M')

    full_range = pd.period_range(d['YearMonth'].min(), d['YearMonth'].max(), freq='M')

    rows = []
    for code, sub in d.groupby('‡∏£‡∏´‡∏±‡∏™'):
        if len(sub) < min_total:
            continue

        # ===== ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (NB) =====
        counts = sub.groupby('YearMonth').size().reindex(full_range, fill_value=0).astype(float)
        y = counts.values
        n_months = len(counts)
        t = np.arange(n_months, dtype=float)
        X = sm.add_constant(t)

        nb_beta0 = np.nan; nb_beta1 = np.nan; nb_p = np.nan; nb_factor = np.nan; alpha_hat = np.nan
        mu_future = np.zeros(horizon, dtype=float)

        if n_months >= min_months and y.sum() > 0:
            try:
                pois = sm.GLM(y, X, family=sm.families.Poisson()).fit()
                mu = pois.fittedvalues
                num = float(((y - mu) ** 2 - y).sum())
                den = float(max((mu ** 2).sum(), 1e-12))
                alpha_hat = max(num / den, alpha_floor)

                nb = sm.GLM(y, X, family=sm.families.NegativeBinomial(alpha=alpha_hat)).fit()
                nb_beta0, nb_beta1 = float(nb.params[0]), float(nb.params[1])
                nb_p = float(nb.pvalues[1])
                nb_factor = float(np.exp(nb_beta1))

                t_future = np.arange(n_months, n_months + horizon, dtype=float)
                eta_future = nb_beta0 + nb_beta1 * t_future
                mu_future = np.exp(eta_future)
            except Exception:
                pass

        # ===== ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á LV3-5 (Logit) =====
        sub['__sev__'] = sub['Impact Level'].astype(str).isin(['3', '4', '5']).astype(int)
        sev_counts = sub.groupby('YearMonth')['__sev__'].sum().reindex(full_range, fill_value=0).astype(float)
        n_counts = sub.groupby('YearMonth').size().reindex(full_range, fill_value=0).astype(float)
        mask = n_counts > 0

        lg_beta0 = np.nan; lg_beta1 = np.nan; lg_p = np.nan; sev_or = np.nan
        p_future = np.full(horizon, np.nan, dtype=float)

        if mask.sum() >= min_months and sev_counts[mask].sum() > 0 and (sev_counts[mask] < n_counts[mask]).any():
            try:
                endog = (sev_counts[mask] / n_counts[mask]).values
                Xt = sm.add_constant(np.arange(n_months)[mask].astype(float))
                logit = sm.GLM(endog, Xt, family=sm.families.Binomial(), freq_weights=n_counts[mask].values).fit()
                lg_beta0, lg_beta1 = float(logit.params[0]), float(logit.params[1])
                lg_p = float(logit.pvalues[1])
                sev_or = float(np.exp(lg_beta1))

                t_future_all = np.arange(n_months, n_months + horizon, dtype=float)
                lin = lg_beta0 + lg_beta1 * t_future_all
                p_future = 1 / (1 + np.exp(-lin))
                p_future = np.clip(p_future, 1e-6, 1 - 1e-6)
            except Exception:
                pass
        else:
            base_p = (sev_counts.sum() / n_counts.sum()) if n_counts.sum() > 0 else 0.0
            p_future = np.full(horizon, base_p, dtype=float)

        expected_all_nextH = float(np.nansum(mu_future))
        expected_sev_nextH = float(np.nansum(mu_future * p_future))

        freq_rising = (nb_beta1 > 0) and (pd.notna(nb_p) and nb_p < 0.05)
        sev_rising = (lg_beta1 > 0) and (pd.notna(lg_p) and lg_p < 0.05)

        rows.append({
            '‡∏£‡∏´‡∏±‡∏™': code,
            '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': sub['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].iloc[0] if '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' in sub else '',
            'Months_Observed': int(n_months),
            'Total_Occurrences': int(y.sum()),
            'NB_alpha_hat': alpha_hat,
            'Freq_NB_Slope': nb_beta1,
            'Freq_p_value': nb_p,
            'Freq_Factor_per_month': nb_factor,  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ ‚Äú‡∏î‡∏¥‡∏ö‚Äù ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô
            'Severity_Logit_Slope': lg_beta1,
            'Severity_p_value': lg_p,
            'Severe_OR_per_month': sev_or,  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ ‚Äú‡∏î‡∏¥‡∏ö‚Äù ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô
            'Expected_All_nextH': expected_all_nextH,
            'Expected_Severe_nextH': expected_sev_nextH,
            'Freq_Rising': freq_rising,
            'Sev_Rising': sev_rising
        })

    if not rows:
        return pd.DataFrame()

    out = pd.DataFrame(rows)

    # ---------- ‡∏ä‡πà‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô: ‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡πÄ‡∏£‡∏¢‡πå/Series ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏≤‡∏£‡πå) ----------
    def _safe_log_pos_arr(x):
        arr = np.asarray(x, dtype=float)
        arr[~np.isfinite(arr)] = 1.0
        arr = np.clip(arr, 1e-12, None)
        return np.log(arr)

    def _norm01_pos_arr(x):
        arr = np.asarray(x, dtype=float)
        arr[~np.isfinite(arr)] = 0.0
        arr = np.clip(arr, 0, None)
        rng = arr.max() - arr.min()
        return (arr - arr.min()) / rng if rng > 0 else np.zeros_like(arr)

    # ---------- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏™‡∏Å‡∏≠‡∏£‡πå ----------
    out['Freq_Factor_per_month'] = pd.to_numeric(out['Freq_Factor_per_month'], errors='coerce').fillna(1.0)
    out['Severe_OR_per_month'] = pd.to_numeric(out['Severe_OR_per_month'], errors='coerce').fillna(1.0)
    out['Expected_Severe_nextH'] = pd.to_numeric(out['Expected_Severe_nextH'], errors='coerce').fillna(0.0)

    # ---------- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏Å‡∏≠‡∏£‡πå‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå (‡πÑ‡∏°‡πà‡∏¢‡∏∏‡πà‡∏á‡∏Å‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏≤‡∏£‡πå) ----------
    out['Score_expected_severe'] = _norm01_pos_arr(out['Expected_Severe_nextH'].values)
    out['Score_freq_growth'] = _norm01_pos_arr(_safe_log_pos_arr(out['Freq_Factor_per_month'].values))
    out['Score_sev_growth'] = _norm01_pos_arr(_safe_log_pos_arr(out['Severe_OR_per_month'].values))

    # bonus ‡∏ñ‡πâ‡∏≤ 2 ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏°‡∏µ‡∏ô‡∏±‡∏¢
    bonus = np.where((out['Freq_Rising']) & (out['Sev_Rising']), 0.05, 0.0)

    out['Priority_Score'] = (
            w_expected_severe * out['Score_expected_severe'] +
            w_freq_growth * out['Score_freq_growth'] +
            w_sev_growth * out['Score_sev_growth'] +
            bonus
    )

    cols = [
        '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Months_Observed', 'Total_Occurrences',
        'Expected_All_nextH', 'Expected_Severe_nextH',
        'Freq_Factor_per_month', 'Freq_p_value',
        'Severe_OR_per_month', 'Severity_p_value',
        'NB_alpha_hat', 'Priority_Score',
        'Freq_Rising', 'Sev_Rising'
    ]
    out = out[cols].sort_values('Priority_Score', ascending=False).reset_index(drop=True)
    return out

# --- REMOVED: PDF generation function ---
# The entire generate_executive_summary_pdf function has been removed.

# ==============================================================================
# STATIC DATA DEFINITIONS
# ==============================================================================
PSG9_FILE_PATH = "PSG9code.xlsx"
SENTINEL_FILE_PATH = "Sentinel2024.xlsx"
ALLCODE_FILE_PATH = "Code2024.xlsx"
psg9_r_codes_for_counting = set()
sentinel_composite_keys = set()
df2 = pd.DataFrame()
try:
    if Path(PSG9_FILE_PATH).is_file():
        PSG9code_df_master = pd.read_excel(PSG9_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in PSG9code_df_master.columns:
            psg9_r_codes_for_counting = set(PSG9code_df_master['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip().unique())
    if Path(SENTINEL_FILE_PATH).is_file():
        Sentinel2024_df = pd.read_excel(SENTINEL_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in Sentinel2024_df.columns and 'Impact' in Sentinel2024_df.columns:
            Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'] = Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
            Sentinel2024_df['Impact'] = Sentinel2024_df['Impact'].astype(str).str.strip()
            Sentinel2024_df.dropna(subset=['‡∏£‡∏´‡∏±‡∏™', 'Impact'], inplace=True)
            sentinel_composite_keys = set((Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'] + '-' + Sentinel2024_df['Impact']).unique())
    if Path(ALLCODE_FILE_PATH).is_file():
        allcode2024_df = pd.read_excel(ALLCODE_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in allcode2024_df.columns and all(
                c in allcode2024_df.columns for c in ["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", "‡∏Å‡∏•‡∏∏‡πà‡∏°", "‡∏´‡∏°‡∏ß‡∏î"]):
            df2 = allcode2024_df[["‡∏£‡∏´‡∏±‡∏™", "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", "‡∏Å‡∏•‡∏∏‡πà‡∏°", "‡∏´‡∏°‡∏ß‡∏î"]].drop_duplicates().copy()
            df2['‡∏£‡∏´‡∏±‡∏™'] = df2['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
except Exception as e:
    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏¥‡∏¢‡∏≤‡∏°: {e}")

risk_color_data = {
    'Category Color': ["Critical", "Critical", "Critical", "Critical", "Critical", "High", "High", "Critical",
                       "Critical", "Critical", "Medium", "Medium", "High", "Critical", "Critical", "Low", "Medium",
                       "Medium", "High", "High", "Low", "Low", "Low", "Medium", "Medium"],
    'Risk Level': ["51", "52", "53", "54", "55", "41", "42", "43", "44", "45", "31", "32", "33", "34", "35", "21",
                   "22", "23", "24", "25", "11", "12", "13", "14", "15"]}
risk_color_df = pd.DataFrame(risk_color_data)
display_cols_common = ['Occurrence Date', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact', 'Impact Level', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î',
                       'Resulting Actions']
month_label = {1: '01 ‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°', 2: '02 ‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå', 3: '03 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°', 4: '04 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô', 5: '05 ‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°', 6: '06 ‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô',
               7: '07 ‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°', 8: '08 ‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°', 9: '09 ‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô', 10: '10 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', 11: '11 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô', 12: '12 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°'}

PSG9_label_dict = {
    1: '01 ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô ‡∏ú‡∏¥‡∏î‡∏Ç‡πâ‡∏≤‡∏á ‡∏ú‡∏¥‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ‡∏ú‡∏¥‡∏î‡∏´‡∏±‡∏ï‡∏ñ‡∏Å‡∏≤‡∏£', 2: '02 ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà',
    3: '03 ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (SSI, VAP,CAUTI, CLABSI)', 4: '04 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î Medication Error ‡πÅ‡∏•‡∏∞ Adverse Drug Event',
    5: '05 ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô ‡∏ú‡∏¥‡∏î‡∏´‡∏°‡∏π‡πà ‡∏ú‡∏¥‡∏î‡∏ä‡∏ô‡∏¥‡∏î', 6: '06 ‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î',
    7: '07 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ', 8: '08 ‡∏Å‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏á‡∏´‡πâ‡∏≠‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£/‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤ ‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô',
    9: '09 ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô'
}

type_name = {'CPS': 'Safe Surgery', 'CPI': 'Infection Prevention and Control', 'CPM': 'Medication & Blood Safety',
             'CPP': 'Patient Care Process', 'CPL': 'Line, Tube & Catheter and Laboratory', 'CPE': 'Emergency Response',
             'CSG': 'Gynecology & Obstetrics diseases and procedure', 'CSS': 'Surgical diseases and procedure',
             'CSM': 'Medical diseases and procedure', 'CSP': 'Pediatric diseases and procedure',
             'CSO': 'Orthopedic diseases and procedure', 'CSD': 'Dental diseases and procedure',
             'GPS': 'Social Media and Communication', 'GPI': 'Infection and Exposure',
             'GPM': 'Mental Health and Mediation', 'GPP': 'Process of work', 'GPL': 'Lane (Traffic) and Legal Issues',
             'GPE': 'Environment and Working Conditions', 'GOS': 'Strategy, Structure, Security',
             'GOI': 'Information Technology & Communication, Internal control & Inventory',
             'GOM': 'Manpower, Management', 'GOP': 'Policy, Process of work & Operation',
             'GOL': 'Licensed & Professional certificate', 'GOE': 'Economy'}

colors2 = np.array([["#e1f5fe", "#f6c8b6", "#dd191d", "#dd191d", "#dd191d", "#dd191d", "#dd191d"],
                    ["#e1f5fe", "#f6c8b6", "#ff8f00", "#ff8f00", "#dd191d", "#dd191d", "#dd191d"],
                    ["#e1f5fe", "#f6c8b6", "#ffee58", "#ffee58", "#ff8f00", "#dd191d", "#dd191d"],
                    ["#e1f5fe", "#f6c8b6", "#42db41", "#ffee58", "#ffee58", "#ff8f00", "#ff8f00"],
                    ["#e1f5fe", "#f6c8b6", "#42db41", "#42db41", "#42db41", "#ffee58", "#ffee58"],
                    ["#e1f5fe", "#f6c8b6", "#f6c8b6", "#f6c8b6", "#f6c8b6", "#f6c8b6", "#f6c8b6"],
                    ["#e1f5fe", "#e1f5fe", "#e1f5fe", "#e1f5fe", "#e1f5fe", "#e1f5fe", "#e1f5fe"]])

# ==============================================================================
# MAIN APP STRUCTURE
# ==============================================================================
def display_admin_page():
    st.title("üîë Admin: Data Upload")
    st.warning("‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
    password = st.text_input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô:", type="password")
    if password == ADMIN_PASSWORD:
        st.success("‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        st.header("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (.xlsx)")
        uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:", type=".xlsx")
        if uploaded_file:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà..."):
                df = load_data(uploaded_file)
                if not df.empty:
                    df.replace('', 'None', inplace=True)
                    df = df.fillna('None')
                    df.rename(columns={'‡∏ß‡∏î‡∏õ.‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î': 'Occurrence Date', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á': 'Impact'}, inplace=True)

                    required_cols = ['Incident', 'Occurrence Date', 'Impact']
                    if not all(col in df.columns for col in required_cols):
                        st.error(f"‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(required_cols)}.")
                        st.stop()

                    df['Impact'] = df['Impact'].astype(str).str.strip()
                    df['‡∏£‡∏´‡∏±‡∏™'] = df['Incident'].astype(str).str.slice(0, 6).str.strip()

                    if not df2.empty:
                        df = pd.merge(df, df2, on='‡∏£‡∏´‡∏±‡∏™', how='left')
                    for col in ["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", "‡∏Å‡∏•‡∏∏‡πà‡∏°", "‡∏´‡∏°‡∏ß‡∏î"]:
                        if col not in df.columns:
                            df[col] = 'N/A'
                        else:
                            df[col].fillna('N/A', inplace=True)

                    df['Occurrence Date'] = pd.to_datetime(df['Occurrence Date'], errors='coerce')
                    df.dropna(subset=['Occurrence Date'], inplace=True)
                    if df.empty:
                        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                        st.stop()

                    impact_level_map = {('A', 'B', '1'): '1', ('C', 'D', '2'): '2', ('E', 'F', '3'): '3',
                                        ('G', 'H', '4'): '4', ('I', '5'): '5'}

                    def map_impact_level_func(val):
                        s_val = str(val)
                        for k, v in impact_level_map.items():
                            if s_val in k: return v
                        return 'N/A'

                    df['Impact Level'] = df['Impact'].apply(map_impact_level_func)

                    max_p = df['Occurrence Date'].max().to_period('M')
                    min_p = df['Occurrence Date'].min().to_period('M')
                    total_month_calc = (max_p.year - min_p.year) * 12 + (max_p.month - min_p.month) + 1

                    df_freq_temp = df['Incident'].value_counts().reset_index()
                    df_freq_temp.columns = ['Incident', 'count']
                    df_freq_temp['Incident Rate/mth'] = (df_freq_temp['count'] / max(1, total_month_calc)).round(1)
                    df = pd.merge(df, df_freq_temp, on="Incident", how='left')

                    conditions_freq = [(df['Incident Rate/mth'] < 2.0), (df['Incident Rate/mth'] < 3.9),
                                       (df['Incident Rate/mth'] < 6.9), (df['Incident Rate/mth'] < 29.9)]
                    choices_freq = ['1', '2', '3', '4']
                    df['Frequency Level'] = np.select(conditions_freq, choices_freq, default='5')

                    df['Risk Level'] = df.apply(
                        lambda row: f"{row['Impact Level']}{row['Frequency Level']}" if pd.notna(
                            row['Impact Level']) and row['Impact Level'] != 'N/A' else 'N/A', axis=1)

                    df = pd.merge(df, risk_color_df, on='Risk Level', how='left')
                    df['Category Color'].fillna('Undefined', inplace=True)

                    df['Incident Type'] = df['Incident'].astype(str).str[:3]
                    df['Month'] = df['Occurrence Date'].dt.month
                    df['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô'] = df['Month'].map(month_label)
                    df['Year'] = df['Occurrence Date'].dt.year.astype(str)

                    PSG9_ID_COL = 'PSG_ID'
                    if 'PSG9code_df_master' in globals() and not PSG9code_df_master.empty and PSG9_ID_COL in PSG9code_df_master.columns:
                        standards_to_merge = PSG9code_df_master[['‡∏£‡∏´‡∏±‡∏™', PSG9_ID_COL]].copy().drop_duplicates(
                            subset=['‡∏£‡∏´‡∏±‡∏™'])
                        standards_to_merge['‡∏£‡∏´‡∏±‡∏™'] = standards_to_merge['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
                        df = pd.merge(df, standards_to_merge, on='‡∏£‡∏´‡∏±‡∏™', how='left')
                        df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] = df[PSG9_ID_COL].map(PSG9_label_dict).fillna(
                            "‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog")
                    else:
                        df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î)"

                    for col in df.select_dtypes(include=['object']).columns:
                        df[col] = df[col].astype(str)

                    df.to_parquet(PERSISTED_DATA_PATH, index=False)
                    st.success(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß")
    elif password:
        st.error("‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!")


def display_executive_dashboard():
    # --- 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    try:
        df = pd.read_parquet(PERSISTED_DATA_PATH)
        df['Occurrence Date'] = pd.to_datetime(df['Occurrence Date'])
    except FileNotFoundError:
        st.warning("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.markdown(f'<p>‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô Admin ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà URL <a href="/?page=admin">?page=admin</a> ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•</p>',
                    unsafe_allow_html=True)
        return

    # --- 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Sidebar ‡πÅ‡∏•‡∏∞‡πÄ‡∏°‡∏ô‡∏π‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    st.sidebar.markdown(
        f"""<div style="display: flex; align-items: center; margin-bottom: 1rem;"><img src="{LOGO_URL}" style="height: 32px; margin-right: 10px;"><h2 style="margin: 0; font-size: 1.7rem; color: #001f3f; font-weight: bold;">HOIA-RR Menu</h2></div>""",
        unsafe_allow_html=True)
    st.sidebar.markdown("---")
    st.sidebar.header("Filter by Date")

    min_date_in_data = df['Occurrence Date'].min().date()
    max_date_in_data = df['Occurrence Date'].max().date()
    today = datetime.now().date()

    filter_option = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤:",
                                         ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏õ‡∏µ‡∏ô‡∏µ‡πâ", "‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™‡∏ô‡∏µ‡πâ", "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß", "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á..."])

    start_date, end_date = min_date_in_data, max_date_in_data

    if filter_option == "‡∏õ‡∏µ‡∏ô‡∏µ‡πâ":
        start_date = today.replace(month=1, day=1)
        end_date = today
    elif filter_option == "‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™‡∏ô‡∏µ‡πâ":
        current_quarter = (today.month - 1) // 3 + 1
        start_date = datetime(today.year, 3 * current_quarter - 2, 1).date()
        end_date = today
    elif filter_option == "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ":
        start_date = today.replace(day=1)
        end_date = today
    elif filter_option == "‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß":
        last_year = today.year - 1
        start_date = datetime(last_year, 1, 1).date()
        end_date = datetime(last_year, 12, 31).date()
    elif filter_option == "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á...":
        start_date, end_date = st.sidebar.date_input(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:",
            [min_date_in_data, max_date_in_data],
            min_value=min_date_in_data,
            max_value=max_date_in_data
        )

    df_filtered = df[(df['Occurrence Date'].dt.date >= start_date) & (df['Occurrence Date'].dt.date <= end_date)].copy()
    df_filtered['Incident Type Name'] = df_filtered['Incident Type'].map(type_name).fillna(df_filtered['Incident Type'])
    if df_filtered.empty:
        st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏∑‡πà‡∏ô")
        return

    min_date_str = df_filtered['Occurrence Date'].min().strftime('%d/%m/%Y')
    max_date_str = df_filtered['Occurrence Date'].max().strftime('%d/%m/%Y')

    max_p = df_filtered['Occurrence Date'].max().to_period('M')
    min_p = df_filtered['Occurrence Date'].min().to_period('M')
    total_month = (max_p.year - min_p.year) * 12 + (max_p.month - min_p.month) + 1
    total_month = max(1, total_month)

    st.sidebar.markdown(f"**‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** {min_date_str} ‡∏ñ‡∏∂‡∏á {max_date_str}")
    st.sidebar.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô:** {total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
    st.sidebar.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå:** {df_filtered.shape[0]:,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    st.sidebar.markdown("---")
    st.sidebar.markdown("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•:")

    analysis_options_list = [
        "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", "Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", "Sentinel Events & Top 10",
        "Risk Matrix (Interactive)", "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏£‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥)",
        "Sankey: ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", "Sankey: ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 9 ‡∏Ç‡πâ‡∏≠",
        "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
        "Persistence Risk Index", "Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£",
        "‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö AI Assistant",
    ]
    if 'selected_analysis' not in st.session_state:
        st.session_state.selected_analysis = analysis_options_list[0]

    for option in analysis_options_list:
        if st.sidebar.button(option, key=f"btn_{option}",
                             type="primary" if st.session_state.selected_analysis == option else "secondary",
                             use_container_width=True):
            st.session_state.selected_analysis = option
            st.rerun()
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"""
                      **‡∏Å‡∏¥‡∏ï‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®:** ‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì¬†
                      - Prof. Shin Ushiro
                      - ‡∏ô‡∏û.‡∏≠‡∏ô‡∏∏‡∏ß‡∏±‡∏í‡∏ô‡πå ‡∏®‡∏∏‡∏†‡∏ä‡∏∏‡∏ï‡∏¥‡∏Å‡∏∏‡∏•¬†
                      - ‡∏ô‡∏û.‡∏Å‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥ ‡πÄ‡∏Å‡∏©‡πÄ‡∏û‡πá‡∏ä‡∏£‡πå¬†
                      - ‡∏û‡∏ç.‡∏õ‡∏¥‡∏¢‡∏ß‡∏£‡∏£‡∏ì ‡∏•‡∏¥‡πâ‡∏°‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡πÄ‡∏•‡∏¥‡∏®¬†
                      - ‡∏†‡∏Å.‡∏õ‡∏£‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏µ‡∏£‡∏∞‡∏≠‡∏ô‡∏±‡∏ô‡∏ï‡∏ß‡∏±‡∏í‡∏ô‡πå¬† ¬†¬†
                      - ‡∏ú‡∏®.‡∏î‡∏£.‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ô‡πå ‡∏Å‡∏∏‡∏•‡∏ß‡∏á‡∏Ñ‡πå (‡∏≠.‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤)

                      ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏¥‡πÄ‡∏£‡∏¥‡πà‡∏° ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ï‡πá‡∏° ‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à ‡∏≠‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ
                      """)

    st.sidebar.markdown("---")
    st.sidebar.markdown(
        '<p style="font-size:12px; color:gray;">*‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå IMPLEMENTING THE¬† HOSPITAL OCCURRENCE/INCIDENT ANALYSIS & RISK REGISTER (HOIA-RR TOOL) IN THAI HOSPITALS: A STUDY ON EFFECTIVE ADOPTION ‡πÇ‡∏î‡∏¢ ‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß‡∏ß‡∏¥‡∏•‡∏≤‡∏®‡∏¥‡∏ô‡∏µ¬† ‡πÄ‡∏Ç‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡∏ß ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÅ‡∏°‡πà‡∏ü‡πâ‡∏≤‡∏´‡∏•‡∏ß‡∏á</p>',
        unsafe_allow_html=True)

    # --- 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard ---
    metrics_data = {}
    metrics_data['total_processed_incidents'] = df_filtered.shape[0]
    metrics_data['total_psg9_incidents_for_metric1'] = \
        df_filtered[df_filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[
            0] if 'psg9_r_codes_for_counting' in globals() else 0
    if 'sentinel_composite_keys' in globals() and sentinel_composite_keys:
        df_filtered['Sentinel code for check'] = df_filtered['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip() + '-' + df_filtered[
            'Impact'].astype(str).str.strip()
        metrics_data['total_sentinel_incidents_for_metric1'] = \
            df_filtered[df_filtered['Sentinel code for check'].isin(sentinel_composite_keys)].shape[0]
    else:
        metrics_data['total_sentinel_incidents_for_metric1'] = 0

    severe_impact_levels_list = ['3', '4', '5']
    df_severe_incidents_calc = df_filtered[df_filtered['Impact Level'].isin(severe_impact_levels_list)].copy()
    metrics_data['total_severe_incidents'] = df_severe_incidents_calc.shape[0]
    if 'Resulting Actions' in df_filtered.columns:
        unresolved_conditions = df_severe_incidents_calc['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
        df_severe_unresolved_calc = df_severe_incidents_calc[unresolved_conditions].copy()
        metrics_data['total_severe_unresolved_incidents_val'] = df_severe_unresolved_calc.shape[0]
        metrics_data['total_severe_unresolved_psg9_incidents_val'] = \
            df_severe_unresolved_calc[df_severe_unresolved_calc['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[
                0] if 'psg9_r_codes_for_counting' in globals() else 0
    else:
        metrics_data['total_severe_unresolved_incidents_val'] = "N/A"
        metrics_data['total_severe_unresolved_psg9_incidents_val'] = "N/A"
    metrics_data['total_month'] = total_month

    df_freq = df_filtered['Incident'].value_counts().reset_index()
    df_freq.columns = ['Incident', 'count']

    # --- 4. PAGE CONTENT ROUTING ---
    selected_analysis = st.session_state.selected_analysis

    if selected_analysis == "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°":
        st.markdown("<h4 style='color: #001f3f;'>‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå:</h4>", unsafe_allow_html=True)

        with st.expander("‡πÅ‡∏™‡∏î‡∏á/‡∏ã‡πà‡∏≠‡∏ô ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Full Data Table)"):
            st.dataframe(df_filtered, hide_index=True, use_container_width=True, column_config={
                "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", format="DD/MM/YYYY")
            })

        dashboard_expander_cols = ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î', 'Resulting Actions']
        date_format_config = {"Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", format="DD/MM/YYYY")}

        total_processed_incidents = metrics_data.get("total_processed_incidents", 0)
        total_psg9_incidents_for_metric1 = metrics_data.get("total_psg9_incidents_for_metric1", 0)
        total_sentinel_incidents_for_metric1 = metrics_data.get("total_sentinel_incidents_for_metric1", 0)
        total_severe_incidents = metrics_data.get("total_severe_incidents", 0)
        total_severe_unresolved_incidents_val = metrics_data.get("total_severe_unresolved_incidents_val", "N/A")
        total_severe_unresolved_psg9_incidents_val = metrics_data.get("total_severe_unresolved_psg9_incidents_val",
                                                                      "N/A")

        df_severe_incidents = df_filtered[df_filtered['Impact Level'].isin(['3', '4', '5'])].copy()
        total_severe_psg9_incidents = \
            df_severe_incidents[df_severe_incidents['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0]

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total", f"{total_processed_incidents:,}")
        with col2:
            st.metric("PSG9", f"{total_psg9_incidents_for_metric1:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_psg9_incidents_for_metric1} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                psg9_df = df_filtered[df_filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                st.dataframe(psg9_df[dashboard_expander_cols], use_container_width=True, hide_index=True,
                             column_config=date_format_config)
        with col3:
            st.metric("Sentinel", f"{total_sentinel_incidents_for_metric1:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_sentinel_incidents_for_metric1} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                if 'Sentinel code for check' in df_filtered.columns:
                    sentinel_df = df_filtered[df_filtered['Sentinel code for check'].isin(sentinel_composite_keys)]
                    st.dataframe(sentinel_df[dashboard_expander_cols], use_container_width=True, hide_index=True,
                                 column_config=date_format_config)

        col4, col5, col6, col7 = st.columns(4)
        with col4:
            st.metric("E-I & 3-5 [all]", f"{total_severe_incidents:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_incidents} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                st.dataframe(df_severe_incidents[dashboard_expander_cols], use_container_width=True, hide_index=True,
                             column_config=date_format_config)
        with col5:
            st.metric("E-I & 3-5 [PSG9]", f"{total_severe_psg9_incidents:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_psg9_incidents} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                severe_psg9_df = df_severe_incidents[df_severe_incidents['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                st.dataframe(severe_psg9_df[dashboard_expander_cols], use_container_width=True, hide_index=True,
                             column_config=date_format_config)
        with col6:
            val_unresolved_all = f"{total_severe_unresolved_incidents_val:,}" if isinstance(
                total_severe_unresolved_incidents_val, int) else "N/A"
            st.metric(f"E-I & 3-5 [all] ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", val_unresolved_all)
            if isinstance(total_severe_unresolved_incidents_val, int) and total_severe_unresolved_incidents_val > 0:
                with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_unresolved_incidents_val} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                    unresolved_df_all = df_filtered[
                        df_filtered['Impact Level'].isin(['3', '4', '5']) & df_filtered['Resulting Actions'].astype(
                            str).isin(['None', '', 'nan'])]
                    st.dataframe(unresolved_df_all[dashboard_expander_cols], use_container_width=True,
                                 hide_index=True,
                                 column_config=date_format_config)
        with col7:
            val_unresolved_psg9 = f"{total_severe_unresolved_psg9_incidents_val:,}" if isinstance(
                total_severe_unresolved_psg9_incidents_val, int) else "N/A"
            st.metric(f"E-I & 3-5 [PSG9] ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", val_unresolved_psg9)
            if isinstance(total_severe_unresolved_psg9_incidents_val,
                          int) and total_severe_unresolved_psg9_incidents_val > 0:
                with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_unresolved_psg9_incidents_val} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                    unresolved_df_all = df_filtered[
                        df_filtered['Impact Level'].isin(['3', '4', '5']) & df_filtered['Resulting Actions'].astype(
                            str).isin(['None', '', 'nan'])]
                    unresolved_df_psg9 = unresolved_df_all[unresolved_df_all['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                    st.dataframe(unresolved_df_psg9[dashboard_expander_cols], use_container_width=True,
                                 hide_index=True,
                                 column_config=date_format_config)
        st.markdown("---")        

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏õ‡∏µ-‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
        monthly_counts = df_filtered.copy()
        monthly_counts['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ'] = monthly_counts['Occurrence Date'].dt.strftime('%Y-%m')

        incident_trend = monthly_counts.groupby('‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ').size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå')
        incident_trend = incident_trend.sort_values(by='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ')

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡πâ‡∏ô
        fig_trend = px.line(
            incident_trend,
            x='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ',
            y='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå',
            title='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô',
            markers=True,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
            labels={'‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ': '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'},
            line_shape='spline'
        )
        fig_trend.update_traces(line=dict(width=3))
        st.plotly_chart(fig_trend, use_container_width=True)
    elif selected_analysis == "Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô":
        st.markdown("<h4 style='color: #001f3f;'>Heatmap: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô</h4>", unsafe_allow_html=True)
        st.info(
            "üí° Heatmap ‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô")

        st.markdown("<h5 style='color: #003366;'>‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ)</h5>",
                    unsafe_allow_html=True)
        heatmap_req_cols = ['‡∏£‡∏´‡∏±‡∏™', '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Month', '‡∏´‡∏°‡∏ß‡∏î']
        if not all(col in df_filtered.columns for col in heatmap_req_cols):
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(heatmap_req_cols)}")
        else:
            df_heat = df_filtered.copy()
            df_heat['incident_label'] = df_heat['‡∏£‡∏´‡∏±‡∏™'] + " | " + df_heat['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].fillna('')

            total_counts = df_heat['incident_label'].value_counts().reset_index()
            total_counts.columns = ['incident_label', 'total_count']

            top_n = st.slider(
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô Heatmap ‡∏£‡∏ß‡∏°:",
                min_value=5, max_value=min(50, len(total_counts)),
                value=min(20, len(total_counts)), step=5, key="top_n_slider"
            )
            top_incident_labels = total_counts.nlargest(top_n, 'total_count')['incident_label']
            df_heat_filtered_view = df_heat[df_heat['incident_label'].isin(top_incident_labels)]
            try:
                heatmap_pivot = pd.pivot_table(df_heat_filtered_view, values='Incident', index='incident_label',
                                               columns='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', aggfunc='count', fill_value=0)
                sorted_month_names = [v for k, v in sorted(month_label.items())]
                available_months = [m for m in sorted_month_names if m in heatmap_pivot.columns]
                if available_months:
                    heatmap_pivot = heatmap_pivot[available_months]
                    heatmap_pivot = heatmap_pivot.reindex(top_incident_labels).dropna()
                    if not heatmap_pivot.empty:
                        fig_heatmap = px.imshow(heatmap_pivot,
                                                labels=dict(x="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", y="‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå", color="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á"),
                                                text_auto=True, aspect="auto", color_continuous_scale='Reds')
                        fig_heatmap.update_layout(title_text=f"Heatmap ‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå Top {top_n} ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
                                                  height=max(600, len(heatmap_pivot.index) * 25), xaxis_title="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô",
                                                  yaxis_title="‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
                        fig_heatmap.update_xaxes(side="top")
                        st.plotly_chart(fig_heatmap, use_container_width=True)
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏£‡∏ß‡∏°: {e}")

            st.markdown("---")

            st.markdown("<h5 style='color: #003366;'>Heatmap ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Safety Goal)</h5>",
                        unsafe_allow_html=True)
            goal_search_terms = {
                "Patient Safety/ Common Clinical Risk": "Patient Safety", "Specific Clinical Risk": "Specific Clinical",
                "Personnel Safety": "Personnel Safety", "Organization Safety": "Organization Safety"
            }

            for display_name, search_term in goal_search_terms.items():
                df_goal_filtered = df_heat[df_heat['‡∏´‡∏°‡∏ß‡∏î'].str.contains(search_term, na=False, case=False)].copy()
                if df_goal_filtered.empty:
                    st.markdown(f"**{display_name}**")
                    st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ô‡∏µ‡πâ")
                    st.markdown("---")
                    continue
                try:
                    goal_pivot = pd.pivot_table(df_goal_filtered, values='Incident', index='incident_label',
                                                columns='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', aggfunc='count', fill_value=0)
                    if not goal_pivot.empty:
                        sorted_month_names = [v for k, v in sorted(month_label.items())]
                        available_months_goal = [m for m in sorted_month_names if m in goal_pivot.columns]
                        if available_months_goal:
                            goal_pivot = goal_pivot[available_months_goal]
                            incident_counts_in_goal = df_goal_filtered['incident_label'].value_counts()
                            sorted_incidents = incident_counts_in_goal.index.tolist()
                            goal_pivot = goal_pivot.reindex(sorted_incidents).dropna(how='all')

                    if goal_pivot.empty:
                        st.markdown(f"**{display_name}**")
                        st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ô‡∏µ‡πâ")
                        st.markdown("---")
                        continue

                    fig_goal = px.imshow(goal_pivot, labels=dict(x="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", y="‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå", color="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"),
                                         text_auto=True, aspect="auto", color_continuous_scale='Oranges')
                    fig_goal.update_layout(title_text=f"<b>{display_name}</b>",
                                           height=max(500, len(goal_pivot.index) * 28), xaxis_title="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô",
                                           yaxis_title="‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
                    fig_goal.update_xaxes(side="top")
                    st.plotly_chart(fig_goal, use_container_width=True)
                    st.markdown("---")
                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{display_name}': {e}")
    elif selected_analysis == "Sentinel Events & Top 10":
        st.markdown("<h4 style='color: #001f3f;'>‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel Events ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö</h4>", unsafe_allow_html=True)
        if 'sentinel_composite_keys' in globals() and sentinel_composite_keys and 'Sentinel code for check' in df_filtered.columns:
            sentinel_events = df_filtered[df_filtered['Sentinel code for check'].isin(sentinel_composite_keys)].copy()

            if not sentinel_events.empty:
                if 'Sentinel2024_df' in globals() and not Sentinel2024_df.empty and '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' in Sentinel2024_df.columns:
                    sentinel_events = pd.merge(sentinel_events,
                                               Sentinel2024_df[['‡∏£‡∏´‡∏±‡∏™', 'Impact', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].rename(
                                                   columns={'‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': 'Sentinel Event Name'}),
                                               on=['‡∏£‡∏´‡∏±‡∏™', 'Impact'], how='left')
                display_sentinel_cols = ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î',
                                         'Resulting Actions']
                if 'Sentinel Event Name' in sentinel_events.columns:
                    display_sentinel_cols.insert(2, 'Sentinel Event Name')
                final_display_cols = [col for col in display_sentinel_cols if col in sentinel_events.columns]
                st.dataframe(sentinel_events[final_display_cols], use_container_width=True, hide_index=True,
                             column_config={
                                 "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", format="DD/MM/YYYY")})
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö Sentinel Events ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sentinel Events ‡πÑ‡∏î‡πâ (‡πÑ‡∏ü‡∏•‡πå Sentinel2024.xlsx ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)")
            

        st.markdown("---")
        st.subheader("Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà)")

        if not df_freq.empty:
            df_freq_top10 = df_freq.nlargest(10, 'count')
            incident_names = df_filtered[['Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
            df_freq_top10 = pd.merge(df_freq_top10, incident_names, on='Incident', how='left')
            st.dataframe(
                df_freq_top10[['Incident', 'count']],
                column_config={
                    "Incident": "‡∏£‡∏´‡∏±‡∏™ Incident",
                    "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
                },
                use_container_width=True,
                hide_index=True
            )
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÑ‡∏î‡πâ")

            
    elif selected_analysis == "Risk Matrix (Interactive)":
        st.subheader("Risk Matrix (Interactive)")

        matrix_data_counts = np.zeros((5, 5), dtype=int)
        impact_level_keys = ['5', '4', '3', '2', '1']
        freq_level_keys = ['1', '2', '3', '4', '5']

        matrix_df = df_filtered[
            df_filtered['Impact Level'].isin(impact_level_keys) &
            df_filtered['Frequency Level'].isin(freq_level_keys)
            ].copy()

        if not matrix_df.empty:
            risk_counts_df = matrix_df.groupby(['Impact Level', 'Frequency Level']).size().reset_index(name='counts')
            for _, row in risk_counts_df.iterrows():
                il_key, fl_key = str(row['Impact Level']), str(row['Frequency Level'])
                row_idx, col_idx = impact_level_keys.index(il_key), freq_level_keys.index(fl_key)
                matrix_data_counts[row_idx, col_idx] = row['counts']

        impact_labels_display = {
            '5': "I / 5<br>Extreme / Death", '4': "G-H / 4<br>Major / Severe",
            '3': "E-F / 3<br>Moderate", '2': "C-D / 2<br>Minor / Low", '1': "A-B / 1<br>Insignificant / No Harm"
        }
        freq_labels_display_short = {"1": "F1", "2": "F2", "3": "F3", "4": "F4", "5": "F5"}
        freq_labels_display_long = {
            "1": "Remote<br>(<2/mth)", "2": "Uncommon<br>(2-3/mth)", "3": "Occasional<br>(4-6/mth)",
            "4": "Probable<br>(7-29/mth)", "5": "Frequent<br>(>=30/mth)"
        }
        impact_to_color_row = {'5': 0, '4': 1, '3': 2, '2': 3, '1': 4}
        freq_to_color_col = {'1': 2, '2': 3, '3': 4, '4': 5, '5': 6}

        cols_header = st.columns([2.2, 1, 1, 1, 1, 1])
        with cols_header[0]:
            st.markdown(
                f"<div style='background-color:{colors2[6, 0]}; color:{get_text_color_for_bg(colors2[6, 0])}; padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:60px; display:flex; align-items:center; justify-content:center;'>Impact / Frequency</div>",
                unsafe_allow_html=True)
        for i, fl_key in enumerate(freq_level_keys):
            with cols_header[i + 1]:
                header_freq_bg_color = colors2[5, freq_to_color_col.get(fl_key, 2) - 1]
                header_freq_text_color = get_text_color_for_bg(header_freq_bg_color)
                st.markdown(
                    f"<div style='background-color:{header_freq_bg_color}; color:{header_freq_text_color}; padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:60px; display:flex; flex-direction: column; align-items:center; justify-content:center;'><div>{freq_labels_display_short.get(fl_key, '')}</div><div style='font-size:0.7em;'>{freq_labels_display_long.get(fl_key, '')}</div></div>",
                    unsafe_allow_html=True)

        for il_key in impact_level_keys:
            cols_data_row = st.columns([2.2, 1, 1, 1, 1, 1])
            row_idx_color = impact_to_color_row[il_key]
            with cols_data_row[0]:
                header_impact_bg_color = colors2[row_idx_color, 1]
                header_impact_text_color = get_text_color_for_bg(header_impact_bg_color)
                st.markdown(
                    f"<div style='background-color:{header_impact_bg_color}; color:{header_impact_text_color}; padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:70px; display:flex; align-items:center; justify-content:center;'>{impact_labels_display[il_key]}</div>",
                    unsafe_allow_html=True)
            for i, fl_key in enumerate(freq_level_keys):
                with cols_data_row[i + 1]:
                    count = matrix_data_counts[impact_level_keys.index(il_key), freq_level_keys.index(fl_key)]
                    cell_bg_color = colors2[row_idx_color, freq_to_color_col[fl_key]]
                    text_color = get_text_color_for_bg(cell_bg_color)
                    st.markdown(
                        f"<div style='background-color:{cell_bg_color}; color:{text_color}; padding:5px; margin:1px; border-radius:3px; text-align:center; font-weight:bold; min-height:40px; display:flex; align-items:center; justify-content:center;'>{count}</div>",
                        unsafe_allow_html=True)
                    if count > 0:
                        button_key = f"view_risk_{il_key}_{fl_key}"
                        if st.button("üëÅÔ∏è", key=button_key, help=f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ - {count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", use_container_width=True):
                            st.session_state.clicked_risk_impact = il_key
                            st.session_state.clicked_risk_freq = fl_key
                            st.session_state.show_incident_table = True
                            st.rerun()
                    else:
                        st.markdown("<div style='height:38px; margin-top:5px;'></div>", unsafe_allow_html=True)

        if st.session_state.get('show_incident_table', False) and st.session_state.clicked_risk_impact is not None:
            il_selected = st.session_state.clicked_risk_impact
            fl_selected = st.session_state.clicked_risk_freq

            df_incidents_in_cell = df_filtered[(df_filtered['Impact Level'].astype(str) == il_selected) & (
                    df_filtered['Frequency Level'].astype(str) == fl_selected)].copy()
            expander_title = f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå: Impact Level {il_selected}, Frequency Level {fl_selected} - ‡∏û‡∏ö {len(df_incidents_in_cell)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
            with st.expander(expander_title, expanded=True):
                st.dataframe(df_incidents_in_cell[display_cols_common], use_container_width=True, hide_index=True)
                if st.button("‡∏õ‡∏¥‡∏î‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", key="clear_risk_selection_button"):
                    st.session_state.show_incident_table = False
                    st.session_state.clicked_risk_impact = None
                    st.session_state.clicked_risk_freq = None
                    st.rerun()

        st.write("---")
        st.subheader("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
        st.info("‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö (I: Impact, F: Frequency) ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏±‡πâ‡∏ô‡πÜ")

        if 'Impact Level' in df_filtered.columns and 'Frequency Level' in df_filtered.columns:
            incident_risk_summary = df_filtered.groupby(['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']).agg(
                max_impact_level=('Impact Level', 'max'),
                frequency_level=('Frequency Level', 'first'),
                total_occurrences=('Incident Rate/mth', 'first')
            ).reset_index()

            def get_color_for_incident(row):
                il_key, fl_key = str(row['max_impact_level']), str(row['frequency_level'])
                if il_key in impact_to_color_row and fl_key in freq_to_color_col:
                    return colors2[impact_to_color_row[il_key], freq_to_color_col[fl_key]]
                return '#808080'

            incident_risk_summary['risk_color_hex'] = incident_risk_summary.apply(get_color_for_incident, axis=1)
            incident_risk_summary = incident_risk_summary.sort_values(by='total_occurrences', ascending=False)

            st.write("---")
            for _, row in incident_risk_summary.iterrows():
                color, text_color = row['risk_color_hex'], get_text_color_for_bg(row['risk_color_hex'])
                risk_label = f"I: {row['max_impact_level']} | F: {row['frequency_level']}"
                col1, col2 = st.columns([1, 6])
                with col1:
                    st.markdown(
                        f'<div style="background-color: {color}; color: {text_color}; font-weight: bold; text-align: center; padding: 8px; border-radius: 5px; height: 100%; display: flex; align-items: center; justify-content: center;">{risk_label}</div>',
                        unsafe_allow_html=True)
                with col2:
                    st.markdown(
                        f"**{row['‡∏£‡∏´‡∏±‡∏™']} | {row['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']}** (‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î: {row.get('total_occurrences', 0):.2f} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Impact Level' ‡∏´‡∏£‡∏∑‡∏≠ 'Frequency Level' ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏µ")

    elif selected_analysis == "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏£‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥)":
        st.markdown("<h4 style='color: #001f3f;'>‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡∏ï‡πà‡∏≤‡∏á‡πÜ)</h4>", unsafe_allow_html=True)
        pastel_color_discrete_map_dimensions = {'Critical': '#FF9999', 'High': '#FFCC99', 'Medium': '#FFFF99',
                                                'Low': '#99FF99', 'Undefined': '#D3D3D3'}
        tab1_v, tab2_v, tab3_v, tab4_v = st.tabs(
            ["üëÅÔ∏èBy Goals (‡∏´‡∏°‡∏ß‡∏î)", "üëÅÔ∏èBy Group (‡∏Å‡∏•‡∏∏‡πà‡∏°)", "üëÅÔ∏èBy Shift (‡πÄ‡∏ß‡∏£)", "üëÅÔ∏èBy Place (‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà)"])

        df_charts = df_filtered.copy()
        df_charts['Count'] = 1

        with tab1_v:
            st.markdown(f"Incidents by Safety Goals ({total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
            if '‡∏´‡∏°‡∏ß‡∏î' in df_charts.columns:
                df_c1 = df_charts[~df_charts['‡∏´‡∏°‡∏ß‡∏î'].isin(
                    ['N/A', 'N/A (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å AllCode ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)', 'N/A (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô AllCode)'])]
                if not df_c1.empty:
                    fig_c1 = px.bar(df_c1.groupby(['‡∏´‡∏°‡∏ß‡∏î', 'Category Color']).size().reset_index(name='Count'),
                                    x='‡∏´‡∏°‡∏ß‡∏î', y='Count', color='Category Color',
                                    color_discrete_map=pastel_color_discrete_map_dimensions)
                    st.plotly_chart(fig_c1, use_container_width=True)
        with tab2_v:
            st.markdown(f"Incidents by Group ({total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
            if '‡∏Å‡∏•‡∏∏‡πà‡∏°' in df_charts.columns:
                df_c2 = df_charts[~df_charts['‡∏Å‡∏•‡∏∏‡πà‡∏°'].isin(
                    ['N/A', 'N/A (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å AllCode ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)', 'N/A (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô AllCode)'])]
                if not df_c2.empty:
                    fig_c2 = px.bar(df_c2.groupby(['‡∏Å‡∏•‡∏∏‡πà‡∏°', 'Category Color']).size().reset_index(name='Count'),
                                    x='‡∏Å‡∏•‡∏∏‡πà‡∏°', y='Count', color='Category Color',
                                    color_discrete_map=pastel_color_discrete_map_dimensions)
                    st.plotly_chart(fig_c2, use_container_width=True)
        with tab3_v:
            st.markdown(f"Incidents by Shift ({total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
            if '‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£' in df_charts.columns:
                df_c3 = df_charts[df_charts['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£'].notna() & ~df_charts['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£'].isin(['None', 'N/A'])]
                if not df_c3.empty:
                    fig_c3 = px.bar(df_c3.groupby(['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£', 'Category Color']).size().reset_index(name='Count'),
                                    x='‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£', y='Count', color='Category Color',
                                    color_discrete_map=pastel_color_discrete_map_dimensions)
                    st.plotly_chart(fig_c3, use_container_width=True)
        with tab4_v:
            st.markdown(f"Incidents by Place ({total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
            if '‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà' in df_charts.columns:
                df_c4 = df_charts[df_charts['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].notna() & ~df_charts['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].isin(['None', 'N/A'])]
                if not df_c4.empty:
                    fig_c4 = px.bar(df_c4.groupby(['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà', 'Category Color']).size().reset_index(name='Count'),
                                    x='‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà', y='Count', color='Category Color',
                                    color_discrete_map=pastel_color_discrete_map_dimensions)
                    st.plotly_chart(fig_c4, use_container_width=True)
    elif selected_analysis == "Sankey: ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°":
        st.markdown("<h4 style='color: #001f3f;'>Sankey Diagram: ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°</h4>", unsafe_allow_html=True)
        st.markdown("""
        <style>
            .plot-container .svg-container .sankey-node text {
                stroke-width: 0 !important; text-shadow: none !important; paint-order: stroke fill;
            }
        </style>
        """, unsafe_allow_html=True)

        req_cols = ['‡∏´‡∏°‡∏ß‡∏î', 'Impact', 'Impact Level', 'Category Color']
        if not all(col in df_filtered.columns for col in req_cols):
            st.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ({', '.join(req_cols)}) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Sankey diagram")
        else:
            sankey_df = df_filtered.copy()

            placeholders = ['None', '', 'N/A', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                            'N/A (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å AllCode ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)',
                            'N/A (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô AllCode ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏ô AllCode)']

            sankey_df = sankey_df[~sankey_df['‡∏´‡∏°‡∏ß‡∏î'].astype(str).isin(placeholders)]

            if sankey_df.empty:
                st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Sankey Diagram ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• '‡∏´‡∏°‡∏ß‡∏î' ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
            else:
                sankey_df['‡∏´‡∏°‡∏ß‡∏î_Node'] = "‡∏´‡∏°‡∏ß‡∏î: " + sankey_df['‡∏´‡∏°‡∏ß‡∏î'].astype(str).str.strip()
                sankey_df['Impact_AI_Node'] = "Impact: " + sankey_df['Impact'].astype(str).str.strip()
                sankey_df.loc[
                    sankey_df['Impact'].astype(str).isin(placeholders), 'Impact_AI_Node'] = "Impact: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ A-I"

                impact_level_display_map = {'1': "Level: 1 (A-B)", '2': "Level: 2 (C-D)", '3': "Level: 3 (E-F)",
                                            '4': "Level: 4 (G-H)", '5': "Level: 5 (I)", 'N/A': "Level: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"}
                sankey_df['Impact_Level_Node'] = sankey_df['Impact Level'].astype(str).str.strip().map(
                    impact_level_display_map).fillna("Level: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
                sankey_df['Risk_Category_Node'] = "Risk: " + sankey_df['Category Color'].astype(str).str.strip()

                node_cols = ['‡∏´‡∏°‡∏ß‡∏î_Node', 'Impact_AI_Node', 'Impact_Level_Node', 'Risk_Category_Node']
                sankey_df.dropna(subset=node_cols, inplace=True)

                labels_muad = sorted(list(sankey_df['‡∏´‡∏°‡∏ß‡∏î_Node'].unique()))
                impact_ai_order = [f"Impact: {i}" for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']] + [
                    "Impact: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ A-I"]
                labels_impact_ai = sorted(list(sankey_df['Impact_AI_Node'].unique()),
                                          key=lambda x: impact_ai_order.index(x) if x in impact_ai_order else 999)
                level_order_map = {"Level: 1 (A-B)": 1, "Level: 2 (C-D)": 2, "Level: 3 (E-F)": 3,
                                   "Level: 4 (G-H)": 4,
                                   "Level: 5 (I)": 5, "Level: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏": 6}
                labels_impact_level = sorted(list(sankey_df['Impact_Level_Node'].unique()),
                                             key=lambda x: level_order_map.get(x, 999))
                risk_order = ["Risk: Critical", "Risk: High", "Risk: Medium", "Risk: Low", "Risk: Undefined"]
                labels_risk_cat = sorted(list(sankey_df['Risk_Category_Node'].unique()),
                                         key=lambda x: risk_order.index(x) if x in risk_order else 999)

                all_labels_ordered = labels_muad + labels_impact_ai + labels_impact_level + labels_risk_cat
                all_labels = list(pd.Series(all_labels_ordered).unique())
                label_to_idx = {label: i for i, label in enumerate(all_labels)}

                source_indices, target_indices, values = [], [], []
                links1 = sankey_df.groupby(['‡∏´‡∏°‡∏ß‡∏î_Node', 'Impact_AI_Node']).size().reset_index(name='value')
                for _, row in links1.iterrows():
                    if row['‡∏´‡∏°‡∏ß‡∏î_Node'] in label_to_idx and row['Impact_AI_Node'] in label_to_idx:
                        source_indices.append(label_to_idx[row['‡∏´‡∏°‡∏ß‡∏î_Node']])
                        target_indices.append(label_to_idx[row['Impact_AI_Node']])
                        values.append(row['value'])

                links2 = sankey_df.groupby(['Impact_AI_Node', 'Impact_Level_Node']).size().reset_index(name='value')
                for _, row in links2.iterrows():
                    if row['Impact_AI_Node'] in label_to_idx and row['Impact_Level_Node'] in label_to_idx:
                        source_indices.append(label_to_idx[row['Impact_AI_Node']])
                        target_indices.append(label_to_idx[row['Impact_Level_Node']])
                        values.append(row['value'])

                links3 = sankey_df.groupby(['Impact_Level_Node', 'Risk_Category_Node']).size().reset_index(
                    name='value')
                for _, row in links3.iterrows():
                    if row['Impact_Level_Node'] in label_to_idx and row['Risk_Category_Node'] in label_to_idx:
                        source_indices.append(label_to_idx[row['Impact_Level_Node']])
                        target_indices.append(label_to_idx[row['Risk_Category_Node']])
                        values.append(row['value'])

                if source_indices:
                    node_colors = []
                    palette1, palette2, palette3 = px.colors.qualitative.Pastel1, px.colors.qualitative.Pastel2, px.colors.qualitative.Set3
                    risk_color_map = {"Risk: Critical": "red", "Risk: High": "orange", "Risk: Medium": "#F7DC6F",
                                      "Risk: Low": "green", "Risk: Undefined": "grey"}
                    for label in all_labels:
                        if label.startswith("‡∏´‡∏°‡∏ß‡∏î:"):
                            node_colors.append(palette1[labels_muad.index(label) % len(palette1)])
                        elif label.startswith("Impact:"):
                            node_colors.append(palette2[labels_impact_ai.index(label) % len(palette2)])
                        elif label.startswith("Level:"):
                            node_colors.append(palette3[labels_impact_level.index(label) % len(palette3)])
                        elif label.startswith("Risk:"):
                            node_colors.append(risk_color_map.get(label, 'grey'))
                        else:
                            node_colors.append('rgba(200,200,200,0.8)')

                    link_colors_rgba = [
                        f'rgba({int(c.lstrip("#")[0:2], 16)},{int(c.lstrip("#")[2:4], 16)},{int(c.lstrip("#")[4:6], 16)},0.3)' if c.startswith(
                            '#') else 'rgba(200,200,200,0.3)' for c in [node_colors[s] for s in source_indices]]

                    fig = go.Figure(data=[go.Sankey(
                        arrangement='snap',
                        node=dict(pad=15, thickness=18, line=dict(color="rgba(0,0,0,0.6)", width=0.75),
                                  label=all_labels, color=node_colors,
                                  hovertemplate='%{label} ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: %{value}<extra></extra>'),
                        link=dict(source=source_indices, target=target_indices, value=values,
                                  color=link_colors_rgba,
                                  hovertemplate='‡∏à‡∏≤‡∏Å %{source.label}<br />‡πÑ‡∏õ‡∏¢‡∏±‡∏á %{target.label}<br />‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: %{value}<extra></extra>')
                    )])
                    fig.update_layout(
                        title_text="<b>‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û Sankey:</b> ‡∏´‡∏°‡∏ß‡∏î -> Impact (A-I) -> Impact Level (1-5) -> Risk Category",
                        font_size=12, height=max(700, len(all_labels) * 18), template='plotly_white',
                        margin=dict(t=60, l=10, r=10, b=20))
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sankey diagram ‡πÑ‡∏î‡πâ (‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)")

    elif selected_analysis == "Sankey: ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 9 ‡∏Ç‡πâ‡∏≠":
        st.markdown("<h4 style='color: #001f3f;'>Sankey Diagram: ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 9 ‡∏Ç‡πâ‡∏≠</h4>",
                    unsafe_allow_html=True)
        st.markdown("""
        <style>
            .plot-container .svg-container .sankey-node text {
                stroke-width: 0 !important; text-shadow: none !important; paint-order: stroke fill;
            }
        </style>
        """, unsafe_allow_html=True)

        required_cols = ['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡∏£‡∏´‡∏±‡∏™', 'Impact', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Category Color']
        if not all(col in df_filtered.columns for col in required_cols):
            st.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ({', '.join(required_cols)}) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Sankey diagram")
        else:
            sankey_df_new = df_filtered.copy()

            placeholders_to_filter = ["‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)",
                                      "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î)"]
            sankey_df_new = sankey_df_new[
                ~sankey_df_new['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].astype(str).isin(placeholders_to_filter)]

            if sankey_df_new.empty:
                st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PSG9 ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
            else:
                psg9_to_cp_gp_map = {PSG9_label_dict[num].strip(): 'CP (‡∏´‡∏°‡∏ß‡∏î‡∏ï‡∏≤‡∏° PSG9)' for num in
                                     [1, 3, 4, 5, 6, 7, 8, 9] if num in PSG9_label_dict}
                psg9_to_cp_gp_map.update(
                    {PSG9_label_dict[num].strip(): 'GP (‡∏´‡∏°‡∏ß‡∏î‡∏ï‡∏≤‡∏° PSG9)' for num in [2] if num in PSG9_label_dict})

                sankey_df_new['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node'] = sankey_df_new['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].map(psg9_to_cp_gp_map)
                sankey_df_new['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node'] = "PSG9: " + sankey_df_new['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç']
                sankey_df_new['‡∏£‡∏´‡∏±‡∏™_Node'] = "‡∏£‡∏´‡∏±‡∏™: " + sankey_df_new['‡∏£‡∏´‡∏±‡∏™']
                sankey_df_new['Impact_AI_Node'] = "Impact: " + sankey_df_new['Impact']
                sankey_df_new['Risk_Category_Node'] = "Risk: " + sankey_df_new['Category Color']
                sankey_df_new['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á_for_hover'] = sankey_df_new[
                    '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].fillna('‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢')

                cols_for_dropna = ['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node', '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node', '‡∏£‡∏´‡∏±‡∏™_Node', 'Impact_AI_Node',
                                   'Risk_Category_Node']
                sankey_df_new.dropna(subset=cols_for_dropna, inplace=True)

                labels_muad_cp_gp_simp = sorted(list(sankey_df_new['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node'].unique()))
                labels_psg9_cat_simp = sorted(list(sankey_df_new['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node'].unique()))
                rh_node_to_desc_map = sankey_df_new.drop_duplicates(subset=['‡∏£‡∏´‡∏±‡∏™_Node']).set_index('‡∏£‡∏´‡∏±‡∏™_Node')[
                    '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á_for_hover'].to_dict()
                labels_rh_simp = sorted(list(sankey_df_new['‡∏£‡∏´‡∏±‡∏™_Node'].unique()))
                labels_impact_ai_simp = sorted(list(sankey_df_new['Impact_AI_Node'].unique()))
                risk_order = ["Risk: Critical", "Risk: High", "Risk: Medium", "Risk: Low", "Risk: Undefined"]
                labels_risk_category = sorted(list(sankey_df_new['Risk_Category_Node'].unique()),
                                              key=lambda x: risk_order.index(x) if x in risk_order else 99)

                all_labels_ordered_simp = labels_muad_cp_gp_simp + labels_psg9_cat_simp + labels_rh_simp + labels_impact_ai_simp + labels_risk_category
                all_labels_simp = list(pd.Series(all_labels_ordered_simp).unique())
                label_to_idx_simp = {label: i for i, label in enumerate(all_labels_simp)}
                customdata_for_nodes_simp = [
                    f"<br>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {str(rh_node_to_desc_map.get(label_node, ''))}" if label_node in rh_node_to_desc_map else ""
                    for label_node in all_labels_simp]

                source_indices_simp, target_indices_simp, values_simp = [], [], []
                links_l1 = sankey_df_new.groupby(['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node', '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node']).size().reset_index(
                    name='value')
                for _, row in links_l1.iterrows():
                    if row['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node'] in label_to_idx_simp and row['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node'] in label_to_idx_simp:
                        source_indices_simp.append(label_to_idx_simp[row['‡∏´‡∏°‡∏ß‡∏î_CP_GP_Node']])
                        target_indices_simp.append(label_to_idx_simp[row['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node']])
                        values_simp.append(row['value'])

                links_l2 = sankey_df_new.groupby(['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node', '‡∏£‡∏´‡∏±‡∏™_Node']).size().reset_index(name='value')
                for _, row in links_l2.iterrows():
                    if row['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node'] in label_to_idx_simp and row['‡∏£‡∏´‡∏±‡∏™_Node'] in label_to_idx_simp:
                        source_indices_simp.append(label_to_idx_simp[row['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG_Node']])
                        target_indices_simp.append(label_to_idx_simp[row['‡∏£‡∏´‡∏±‡∏™_Node']])
                        values_simp.append(row['value'])

                links_l3 = sankey_df_new.groupby(['‡∏£‡∏´‡∏±‡∏™_Node', 'Impact_AI_Node']).size().reset_index(name='value')
                for _, row in links_l3.iterrows():
                    if row['‡∏£‡∏´‡∏±‡∏™_Node'] in label_to_idx_simp and row['Impact_AI_Node'] in label_to_idx_simp:
                        source_indices_simp.append(label_to_idx_simp[row['‡∏£‡∏´‡∏±‡∏™_Node']])
                        target_indices_simp.append(label_to_idx_simp[row['Impact_AI_Node']])
                        values_simp.append(row['value'])

                links_l4 = sankey_df_new.groupby(['Impact_AI_Node', 'Risk_Category_Node']).size().reset_index(
                    name='value')
                for _, row in links_l4.iterrows():
                    if row['Impact_AI_Node'] in label_to_idx_simp and row['Risk_Category_Node'] in label_to_idx_simp:
                        source_indices_simp.append(label_to_idx_simp[row['Impact_AI_Node']])
                        target_indices_simp.append(label_to_idx_simp[row['Risk_Category_Node']])
                        values_simp.append(row['value'])

                if source_indices_simp:
                    node_colors_simp = []
                    palette_l1, palette_l2, palette_l3, palette_l4 = px.colors.qualitative.Bold, px.colors.qualitative.Pastel, px.colors.qualitative.Vivid, px.colors.qualitative.Set3
                    risk_cat_color_map = {"Risk: Critical": "red", "Risk: High": "orange",
                                          "Risk: Medium": "#F7DC6F",
                                          "Risk: Low": "green", "Risk: Undefined": "grey"}
                    for label_node in all_labels_simp:
                        if label_node in labels_muad_cp_gp_simp:
                            node_colors_simp.append(
                                palette_l1[labels_muad_cp_gp_simp.index(label_node) % len(palette_l1)])
                        elif label_node in labels_psg9_cat_simp:
                            node_colors_simp.append(
                                palette_l2[labels_psg9_cat_simp.index(label_node) % len(palette_l2)])
                        elif label_node in labels_rh_simp:
                            node_colors_simp.append(palette_l3[labels_rh_simp.index(label_node) % len(palette_l3)])
                        elif label_node in labels_impact_ai_simp:
                            node_colors_simp.append(
                                palette_l4[labels_impact_ai_simp.index(label_node) % len(palette_l4)])
                        elif label_node in labels_risk_category:
                            node_colors_simp.append(risk_cat_color_map.get(label_node, 'grey'))
                        else:
                            node_colors_simp.append('rgba(200,200,200,0.8)')

                    link_colors_simp = []
                    default_link_color_simp = 'rgba(200,200,200,0.35)'
                    for s_idx in source_indices_simp:
                        try:
                            hex_color = node_colors_simp[s_idx]
                            h = hex_color.lstrip('#')
                            rgb_tuple = tuple(int(h[i:i + 2], 16) for i in (0, 2, 4))
                            link_colors_simp.append(f'rgba({rgb_tuple[0]},{rgb_tuple[1]},{rgb_tuple[2]},0.3)')
                        except:
                            link_colors_simp.append(default_link_color_simp)

                    fig_sankey_psg9_simplified = go.Figure(data=[go.Sankey(
                        arrangement='snap',
                        node=dict(pad=10, thickness=15, line=dict(color="rgba(0,0,0,0.4)", width=0.4),
                                  label=all_labels_simp, color=node_colors_simp,
                                  customdata=customdata_for_nodes_simp,
                                  hovertemplate='<b>%{label}</b><br>‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: %{value}%{customdata}<extra></extra>'),
                        link=dict(source=source_indices_simp, target=target_indices_simp, value=values_simp,
                                  color=link_colors_simp,
                                  hovertemplate='‡∏à‡∏≤‡∏Å %{source.label}<br />‡πÑ‡∏õ‡∏¢‡∏±‡∏á %{target.label}<br />‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: %{value}<extra></extra>')
                    )])
                    fig_sankey_psg9_simplified.update_layout(
                        title_text="<b>‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û SANKEY:</b> CP/GP -> ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9 -> ‡∏£‡∏´‡∏±‡∏™ -> Impact -> Risk Category",
                        font_size=11, height=max(800, len(all_labels_simp) * 12 + 200),
                        template='plotly_white', margin=dict(t=70, l=10, r=10, b=20)
                    )
                    st.plotly_chart(fig_sankey_psg9_simplified, use_container_width=True)
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sankey diagram (PSG9) ‡πÑ‡∏î‡πâ")
    elif selected_analysis == "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals":
        st.markdown("<h4 style='color: #001f3f;'>‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (Safety Goals)</h4>",
                    unsafe_allow_html=True)

        goal_definitions = {
            "Patient Safety/ Common Clinical Risk": "P:Patient Safety Goals ‡∏´‡∏£‡∏∑‡∏≠ Common Clinical Risk Incident",
            "Specific Clinical Risk": "S:Specific Clinical Risk Incident",
            "Personnel Safety": "P:Personnel Safety Goals",
            "Organization Safety": "O:Organization Safety Goals"
        }

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ---
        for display_name, cat_name in goal_definitions.items():
            st.markdown(f"##### {display_name}")
            is_org_safety = (display_name == "Organization Safety")
            summary_table = create_goal_summary_table(
                df_filtered,
                cat_name,
                e_up_non_numeric_levels_param=[] if is_org_safety else ['A', 'B', 'C', 'D'],
                e_up_numeric_levels_param=['1', '2'] if is_org_safety else None,
                is_org_safety_table=is_org_safety
            )
            if summary_table is not None and not summary_table.empty:
                st.dataframe(summary_table, use_container_width=True)
            else:
                st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{display_name}' ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö % E-up (‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤) ---
        st.markdown("---")
        st.subheader("üìä ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (% E-up) ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠")

        severe_levels = ['E', 'F', 'G', 'H', 'I', '3', '4', '5']
        valid_goals = [goal for goal in df_filtered['‡∏´‡∏°‡∏ß‡∏î'].unique() if
                       goal and goal not in ['N/A', 'N/A (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å AllCode ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)',
                                             'N/A (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô AllCode)']]

        for goal in valid_goals:
            st.markdown(f"#### {goal}")
            goal_df = df_filtered[df_filtered['‡∏´‡∏°‡∏ß‡∏î'] == goal].copy()
            summary = goal_df.groupby('Incident Type Name').apply(
                lambda x: (x['Impact'].isin(severe_levels).sum() / len(x) * 100) if len(x) > 0 else 0
            ).reset_index(name='‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up')
            summary = summary[summary['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] > 0].sort_values(by='‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up', ascending=True)

            if summary.empty:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-up) ‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ô‡∏µ‡πâ")
                continue

            fig = px.bar(
                summary,
                x='‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up',
                y='Incident Type Name',
                orientation='h',
                title=f"‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î {goal}",
                labels={'Incident Type Name': '‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up': '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (%)'},
                text_auto='.2f',
                color='‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up',
                color_continuous_scale='Reds'
            )
            fig.update_layout(yaxis_title=None, xaxis_ticksuffix="%")
            st.plotly_chart(fig, use_container_width=True)

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏£‡∏≤‡∏ü Sunburst (‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤) ---
        st.markdown("---")
        st.subheader("‚òÄÔ∏è ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÅ‡∏ö‡∏ö Sunburst")

        total_counts = df_filtered.groupby(['‡∏´‡∏°‡∏ß‡∏î', 'Incident Type Name']).size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î')
        severe_df = df_filtered[df_filtered['Impact'].isin(severe_levels)]
        severe_counts = severe_df.groupby(['‡∏´‡∏°‡∏ß‡∏î', 'Incident Type Name']).size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô E-up')
        summary_df = pd.merge(total_counts, severe_counts, on=['‡∏´‡∏°‡∏ß‡∏î', 'Incident Type Name'], how='left').fillna(0)
        summary_df['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = (summary_df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô E-up'] / summary_df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] * 100)
        summary_df = summary_df[summary_df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] > 0]

        if summary_df.empty:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Sunburst")
        else:
            fig_sunburst = px.sunburst(
                summary_df,
                path=['‡∏´‡∏°‡∏ß‡∏î', 'Incident Type Name'],
                values='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î',
                color='‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up',
                color_continuous_scale='YlOrRd',
                hover_data={'‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up': ':.2f'},
                title="‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (‡∏Ç‡∏ô‡∏≤‡∏î = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°, ‡∏™‡∏µ = % E-up)"
            )
            fig_sunburst.update_traces(textinfo="label+percent entry")
            st.plotly_chart(fig_sunburst, use_container_width=True)

    elif selected_analysis == "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç":
        st.markdown("<h4 style='color: #001f3f;'>‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç</h4>", unsafe_allow_html=True)

        if 'Resulting Actions' not in df_filtered.columns or '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' not in df_filtered.columns:
            st.error(
                "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Resulting Actions' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        else:
            tab_psg9, tab_groups, tab_summary, tab_waitlist = st.tabs(
                ["üëÅÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9", "üëÅÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å (C/G)",
                 "üëÅÔ∏è ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5)", "üëÅÔ∏è ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç(‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)"])

            with tab_psg9:
                st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (PSG9)")
                psg9_summary_table = create_psg9_summary_table(df_filtered)
                if psg9_summary_table is not None and not psg9_summary_table.empty:
                    st.dataframe(psg9_summary_table, use_container_width=True)
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 9 ‡∏Ç‡πâ‡∏≠‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")

                st.markdown("---")
                st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9")

                psg9_categories = {k: v for k, v in PSG9_label_dict.items() if
                                   v in df_filtered['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].unique()}

                for psg9_id, psg9_name in psg9_categories.items():
                    psg9_df = df_filtered[df_filtered['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] == psg9_name]
                    total_count = len(psg9_df)
                    resolved_df = psg9_df[~psg9_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                    resolved_count = len(resolved_df)
                    unresolved_count = total_count - resolved_count

                    expander_title = f"{psg9_name} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                    with st.expander(expander_title):
                        c1, c2, c3 = st.columns(3)
                        c1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total_count:,}")
                        c2.metric("‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß", f"{resolved_count:,}")
                        c3.metric("‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", f"{unresolved_count:,}")

                        if total_count > 0:
                            tab_resolved, tab_unresolved = st.tabs(
                                [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                            with tab_resolved:
                                if resolved_count > 0:
                                    st.dataframe(
                                        resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                        hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                            with tab_unresolved:
                                if unresolved_count > 0:
                                    st.dataframe(
                                        psg9_df[psg9_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])][
                                            ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']],
                                        hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")

            with tab_groups:
                st.subheader("‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢")
                st.markdown("#### ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å (‡∏£‡∏´‡∏±‡∏™‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ C)")
                df_clinical = df_filtered[df_filtered['‡∏£‡∏´‡∏±‡∏™'].str.startswith('C', na=False)].copy()

                if df_clinical.empty:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° Clinical")
                else:
                    clinical_categories = sorted([cat for cat in df_clinical['‡∏´‡∏°‡∏ß‡∏î'].unique() if cat and pd.notna(cat)])
                    for category in clinical_categories:
                        category_df = df_clinical[df_clinical['‡∏´‡∏°‡∏ß‡∏î'] == category]
                        total_count = len(category_df)
                        resolved_df = category_df[
                            ~category_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                        resolved_count = len(resolved_df)
                        unresolved_count = total_count - resolved_count

                        expander_title = f"{category} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                        with st.expander(expander_title):
                            tab_resolved, tab_unresolved = st.tabs(
                                [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                            with tab_resolved:
                                if resolved_count > 0:
                                    st.dataframe(
                                        resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                        hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                            with tab_unresolved:
                                if unresolved_count > 0:
                                    st.dataframe(category_df[category_df['Resulting Actions'].astype(str).isin(
                                        ['None', '', 'nan'])][
                                                     ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']],
                                                 hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")

                st.markdown("---")
                st.markdown("#### ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏£‡∏´‡∏±‡∏™‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ G)")
                df_general = df_filtered[df_filtered['‡∏£‡∏´‡∏±‡∏™'].str.startswith('G', na=False)].copy()

                if df_general.empty:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° General")
                else:
                    general_categories = sorted([cat for cat in df_general['‡∏´‡∏°‡∏ß‡∏î'].unique() if cat and pd.notna(cat)])
                    for category in general_categories:
                        category_df = df_general[df_general['‡∏´‡∏°‡∏ß‡∏î'] == category]
                        total_count = len(category_df)
                        resolved_df = category_df[
                            ~category_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                        resolved_count = len(resolved_df)
                        unresolved_count = total_count - resolved_count

                        expander_title = f"{category} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                        with st.expander(expander_title):
                            tab_resolved, tab_unresolved = st.tabs(
                                [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                            with tab_resolved:
                                if resolved_count > 0:
                                    st.dataframe(
                                        resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                        hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                            with tab_unresolved:
                                if unresolved_count > 0:
                                    st.dataframe(category_df[category_df['Resulting Actions'].astype(str).isin(
                                        ['None', '', 'nan'])][
                                                     ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']],
                                                 hide_index=True, use_container_width=True, column_config={
                                            "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                               format="DD/MM/YYYY")})
                                else:
                                    st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")
            with tab_summary:
                st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5)")

                total_severe_incidents = metrics_data.get("total_severe_incidents", 0)
                total_severe_unresolved_incidents_val = metrics_data.get("total_severe_unresolved_incidents_val", 0)

                severe_df = df_filtered[df_filtered['Impact Level'].isin(['3', '4', '5'])]
                total_severe_psg9_incidents = severe_df[severe_df['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0]
                total_severe_unresolved_psg9_incidents_val = metrics_data.get(
                    "total_severe_unresolved_psg9_incidents_val", 0)

                val_row3_total_pct = (
                                             total_severe_unresolved_incidents_val / total_severe_incidents * 100) if total_severe_incidents > 0 else 0
                val_row3_psg9_pct = (
                                            total_severe_unresolved_psg9_incidents_val / total_severe_psg9_incidents * 100) if total_severe_psg9_incidents > 0 else 0

                summary_action_data = [
                    {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "1. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á E-I & 3-5", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_severe_incidents:,}",
                     "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{total_severe_psg9_incidents:,}"},
                    {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "2. ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå E-I & 3-5 ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                     "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_severe_unresolved_incidents_val:,}",
                     "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{total_severe_unresolved_psg9_incidents_val:,}"},
                    {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "3. % ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå E-I & 3-5 ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                     "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{val_row3_total_pct:.2f}%", "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{val_row3_psg9_pct:.2f}%"}
                ]
                st.dataframe(pd.DataFrame(summary_action_data).set_index('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î'), use_container_width=True)

            with tab_waitlist:
                st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)")
                unresolved_df = df_filtered[df_filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])].copy()

                if unresolved_df.empty:
                    st.success("üéâ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö!")
                else:
                    st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{len(unresolved_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    severity_order = ['Critical', 'High', 'Medium', 'Low', 'Undefined']
                    for severity in severity_order:
                        severity_df = unresolved_df[unresolved_df['Category Color'] == severity]
                        if not severity_df.empty:
                            with st.expander(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á: {severity} ({len(severity_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                                display_cols = ['Occurrence Date', 'Incident', 'Impact',
                                                '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']

                                st.dataframe(severity_df[display_cols], use_container_width=True, hide_index=True,
                                             column_config={
                                                 "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                                    format="DD/MM/YYYY")})
    elif selected_analysis == "Persistence Risk Index":
        st.markdown("<h4 style='color: #001f3f;'>‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (Persistence Risk Index)</h4>",
                    unsafe_allow_html=True)
        st.info(
            "‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏π‡∏á ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∞‡∏ö‡∏ö")

        persistence_df = calculate_persistence_risk_score(df_filtered, total_month)

        if not persistence_df.empty:
            display_df_persistence = persistence_df.rename(columns={
                'Persistence_Risk_Score': '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á',
                'Average_Ordinal_Risk_Score': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢',
                'Incident_Rate_Per_Month': '‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î (‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)',
                'Total_Occurrences': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'
            })
            st.dataframe(
                display_df_persistence[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á',
                                        '‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î (‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î']],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢": st.column_config.NumberColumn(format="%.2f"),
                    "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î (‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)": st.column_config.NumberColumn(format="%.2f"),
                    "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á": st.column_config.ProgressColumn(
                        "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á",
                        help="‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á",
                        min_value=0,
                        max_value=2,  # ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏≤‡∏á‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ñ‡∏∑‡∏≠ 2 (Frequency Score = 1, Severity Score = 1)
                        format="%.2f"
                    )
                }
            )
            st.markdown("---")
            st.markdown("##### ‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á")
            fig = px.scatter(
                persistence_df,
                x="Average_Ordinal_Risk_Score",
                y="Incident_Rate_Per_Month",
                size="Total_Occurrences",
                color="Persistence_Risk_Score",
                hover_name="‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á",
                color_continuous_scale=px.colors.sequential.Reds,
                size_max=60,
                labels={
                    "Average_Ordinal_Risk_Score": "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏ß‡∏≤‡∏¢‡∏¥‡πà‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)",
                    "Incident_Rate_Per_Month": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏ö‡πà‡∏≠‡∏¢)",
                    "Persistence_Risk_Score": "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á",
                    "Total_Occurrences": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                },
                title="‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà vs ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á"
            )
            fig.update_layout(xaxis_title="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", yaxis_title="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")

    elif selected_analysis == "Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô":
        st.markdown("<h4 style='color:#001f3f;'>Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô</h4>",
                    unsafe_allow_html=True)

        if 'prioritize_incidents_nb_logit_v2' not in globals():
            st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `prioritize_incidents_nb_logit_v2` ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î")
        else:
            c1, c2, c3 = st.columns(3)
            with c1:
                horizon = st.slider("‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏î‡∏∑‡∏≠‡∏ô):", 1, 12, 3, 1, key="ew_horizon")
            with c2:
                min_months = st.slider("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:", 3, 12, 4, 1, key="ew_min_months")
            with c3:
                min_total = st.slider("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∞‡∏™‡∏°/‡∏£‡∏´‡∏±‡∏™:", 3, 200, 5, 1, key="ew_min_total")

            st.markdown("**‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô = 1 ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)**")
            c4, c5, c6 = st.columns(3)
            with c4:
                w1 = st.slider("‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (‡∏ê‡∏≤‡∏ô 0.7)", 0.0, 1.0, 0.7, 0.05, key="ew_w1")
            with c5:
                w2 = st.slider("‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (‡∏ê‡∏≤‡∏ô 0.2)", 0.0, 1.0, 0.2, 0.05, key="ew_w2")
            with c6:
                w3 = st.slider("‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (‡∏ê‡∏≤‡∏ô 0.1)", 0.0, 1.0, 0.1, 0.05, key="ew_w3")

            _sumw = max(w1 + w2 + w3, 1e-9)
            w1n, w2n, w3n = w1 / _sumw, w2 / _sumw, w3 / _sumw

            try:
                res = prioritize_incidents_nb_logit_v2(
                    df_filtered,
                    horizon=horizon,
                    min_months=min_months,
                    min_total=min_total,
                    w_expected_severe=w1n,
                    w_freq_growth=w2n,
                    w_sev_growth=w3n
                )
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {e}")
                res = pd.DataFrame()

            if res.empty:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Early Warning ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
            else:
                topn = st.slider("‡πÅ‡∏™‡∏î‡∏á Top-N:", 5, 50, 10, 5, key="ew_topn")
                only_sig = st.checkbox("‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ñ‡∏µ‡πà‚Üë ‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‚Üë)", value=False,
                                       key="ew_only_sig")

                show = res.copy()
                if only_sig:
                    show = show[
                        (show['Freq_p_value'].notna() & (show['Freq_p_value'] < 0.05)) |
                        (show['Severity_p_value'].notna() & (show['Severity_p_value'] < 0.05))
                        ]

                st.dataframe(
                    show.head(topn),
                    use_container_width=True, hide_index=True,
                    column_config={
                        '‡∏£‡∏´‡∏±‡∏™': st.column_config.Column("‡∏£‡∏´‡∏±‡∏™"),
                        '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': st.column_config.Column("‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå", width="large"),
                        'Months_Observed': st.column_config.NumberColumn("‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", format="%d"),
                        'Total_Occurrences': st.column_config.NumberColumn("‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∞‡∏™‡∏°", format="%d"),
                        'Expected_Severe_nextH': st.column_config.NumberColumn(f"‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå '‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á' (H={horizon})",
                                                                               format="%.1f"),
                        'Freq_Factor_per_month': st.column_config.NumberColumn("‡πÄ‡∏ó‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", format="%.2f"),
                        'Freq_p_value': st.column_config.NumberColumn("p(‡∏ñ‡∏µ‡πà‚Üë)", format="%.3f"),
                        'Severe_OR_per_month': st.column_config.NumberColumn("Odds ‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", format="%.2f"),
                        'Severity_p_value': st.column_config.NumberColumn("p(‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‚Üë)", format="%.3f"),
                        'Priority_Score': st.column_config.ProgressColumn("Priority", min_value=0,
                                                                          max_value=show['Priority_Score'].max(),
                                                                          format="%.3f"),
                    }
                )

                with st.expander("‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö (‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏¢‡πà‡∏≠)"):
                    st.markdown(f"""
                         - **‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå '‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á' (H={horizon})**: ‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (‡∏£‡∏∞‡∏î‡∏±‡∏ö 3‚Äì5) ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏≠‡∏µ‡∏Å {horizon} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤
                         - **Priority Score**: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á '‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô', ‡πÅ‡∏•‡∏∞ '‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô'
                         - **p(‡∏ñ‡∏µ‡πà‚Üë)** ‡πÅ‡∏•‡∏∞ **p(‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‚Üë)**: ‡∏Ñ‡πà‡∏≤ p-value ‡∏¢‡∏¥‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô < 0.05) ‡∏¢‡∏¥‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                         """)

    elif selected_analysis == "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£":
        st.markdown("<h4 style='color: #001f3f;'>‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£</h4>", unsafe_allow_html=True)
        st.markdown(f"**‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á:** ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")
        st.markdown(f"**‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:** {min_date_str} ‡∏ñ‡∏∂‡∏á {max_date_str} (‡∏£‡∏ß‡∏° {total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
        st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:** {metrics_data.get('total_processed_incidents', 0):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        st.markdown("---")

        st.subheader("1. ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°")
        col1_m, col2_m, col3_m, col4_m, col5_m = st.columns(5)
        with col1_m:
            st.metric("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{metrics_data.get('total_processed_incidents', 0):,}")
        with col2_m:
            st.metric("Sentinel Events", f"{metrics_data.get('total_sentinel_incidents_for_metric1', 0):,}")
        with col3_m:
            st.metric("‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ø 9 ‡∏Ç‡πâ‡∏≠", f"{metrics_data.get('total_psg9_incidents_for_metric1', 0):,}")
        with col4_m:
            st.metric("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á (E-I & 3-5)", f"{metrics_data.get('total_severe_incidents', 0):,}")
        with col5_m:
            val_unresolved = metrics_data.get('total_severe_unresolved_incidents_val', 'N/A')
            st.metric("‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á & ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                      f"{val_unresolved:,}" if isinstance(val_unresolved, int) else val_unresolved)
        st.markdown("---")

        st.subheader("2. Risk Matrix ‡πÅ‡∏•‡∏∞ Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
        col_matrix, col_top10 = st.columns(2)
        with col_matrix:
            st.markdown("##### Risk Matrix")
            impact_level_keys = ['5', '4', '3', '2', '1']
            freq_level_keys = ['1', '2', '3', '4', '5']
            matrix_df = df_filtered[
                df_filtered['Impact Level'].isin(impact_level_keys) & df_filtered['Frequency Level'].isin(
                    freq_level_keys)]
            if not matrix_df.empty:
                matrix_data = pd.crosstab(matrix_df['Impact Level'], matrix_df['Frequency Level'])
                matrix_data = matrix_data.reindex(index=impact_level_keys, columns=freq_level_keys, fill_value=0)
                impact_labels = {'5': "5 (Extreme)", '4': "4 (Major)", '3': "3 (Moderate)", '2': "2 (Minor)",
                                 '1': "1 (Insignificant)"}
                freq_labels = {'1': "F1", '2': "F2", '3': "F3", '4': "F4", '5': "F5"}
                st.table(matrix_data.rename(index=impact_labels, columns=freq_labels))
        with col_top10:
            st.markdown("##### Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà)")
            if not df_freq.empty:
                df_freq_top10 = df_freq.nlargest(10, 'count').copy()
                display_top10 = pd.merge(df_freq_top10,
                                         df_filtered[['Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates(),
                                         on='Incident', how='left')
                st.dataframe(display_top10[['Incident', 'count']], hide_index=True,
                             use_container_width=True,
                             column_config={"Incident": "‡∏£‡∏´‡∏±‡∏™",
                                            "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"})
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Top 10")
        st.markdown("---")

        st.subheader("3. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel Events")
        if 'Sentinel code for check' in df_filtered.columns:
            sentinel_events_df = df_filtered[df_filtered['Sentinel code for check'].isin(sentinel_composite_keys)]
            if not sentinel_events_df.empty:
                st.dataframe(sentinel_events_df[['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']],
                             hide_index=True, use_container_width=True,
                             column_config={"Occurrence Date": "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", "Incident": "‡∏£‡∏´‡∏±‡∏™", "Impact": "‡∏£‡∏∞‡∏î‡∏±‡∏ö",
                                            "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"})
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö Sentinel Events ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        st.markdown("---")

        st.subheader("4. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 9 ‡∏Ç‡πâ‡∏≠")
        psg9_summary_table = create_psg9_summary_table(df_filtered)
        if psg9_summary_table is not None and not psg9_summary_table.empty:
            st.table(psg9_summary_table)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PSG9 ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
        st.markdown("---")

        st.subheader("5. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5) ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
        if 'Resulting Actions' in df_filtered.columns:
            unresolved_severe_df = df_filtered[
                df_filtered['Impact Level'].isin(['3', '4', '5']) &
                df_filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
                ]
            if not unresolved_severe_df.empty:
                display_cols_unresolved = ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î']
                st.dataframe(
                    unresolved_severe_df[display_cols_unresolved],
                    hide_index=True,
                    use_container_width=True,
                    column_config={
                        "Occurrence Date": st.column_config.DatetimeColumn(
                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                            format="DD/MM/YYYY",
                        ),
                        "Incident": "‡∏£‡∏´‡∏±‡∏™",
                        "Impact": "‡∏£‡∏∞‡∏î‡∏±‡∏ö",
                        "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
                    }
                )
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
        
        st.subheader("6. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Safety Goals")
        goal_definitions = {
            "Patient Safety/ Common Clinical Risk": "P:Patient Safety Goals ‡∏´‡∏£‡∏∑‡∏≠ Common Clinical Risk Incident",
            "Specific Clinical Risk": "S:Specific Clinical Risk Incident",
            "Personnel Safety": "P:Personnel Safety Goals", "Organization Safety": "O:Organization Safety Goals"}
        for display_name, cat_name in goal_definitions.items():
            st.markdown(f"##### {display_name}")
            is_org_safety = (display_name == "Organization Safety")
            summary_table = create_goal_summary_table(df_filtered, cat_name,
                                                      e_up_non_numeric_levels_param=[] if is_org_safety else ['A', 'B', 'C', 'D'],
                                                      e_up_numeric_levels_param=['1', '2'] if is_org_safety else None,
                                                      is_org_safety_table=is_org_safety)
            if summary_table is not None and not summary_table.empty:
                st.table(summary_table)
            else:
                st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{display_name}'")
        st.markdown("---")

        st.subheader("7. Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÉ‡∏ô 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ (Top 5)")
        st.write(
            "‡πÅ‡∏™‡∏î‡∏á Top 5 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á, ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï")
        if 'prioritize_incidents_nb_logit_v2' in globals():
            early_warning_df = prioritize_incidents_nb_logit_v2(df_filtered, horizon=3, min_months=4, min_total=5)
            if not early_warning_df.empty:
                top_ew_incidents = early_warning_df.head(5).copy()
                display_ew_df = top_ew_incidents.rename(
                    columns={'‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', 'Priority_Score': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç',
                             'Expected_Severe_nextH': '‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (3 ‡∏î.)'})
                st.dataframe(
                    display_ew_df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (3 ‡∏î.)']],
                    column_config={
                        "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç": st.column_config.ProgressColumn("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", format="%.3f", min_value=0,
                                                                          max_value=float(
                                                                              display_ew_df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].max())),
                        "‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (3 ‡∏î.)": st.column_config.NumberColumn(format="%.2f")
                    },
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Early Warning")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Early Warning")
        st.markdown("---")

        st.subheader("8. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (Persistence Risk - Top 5)")
        st.write("‡πÅ‡∏™‡∏î‡∏á Top 5 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏π‡∏á ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∞‡∏ö‡∏ö")
        persistence_df_exec = calculate_persistence_risk_score(df_filtered, total_month)
        if not persistence_df_exec.empty:
            top_persistence_incidents = persistence_df_exec.head(5)
            display_df_persistence = top_persistence_incidents.rename(
                columns={'Persistence_Risk_Score': '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á',
                         'Average_Ordinal_Risk_Score': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢'})
            st.dataframe(
                display_df_persistence[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á']],
                column_config={
                    "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢": st.column_config.NumberColumn(format="%.2f"),
                    "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á": st.column_config.ProgressColumn("‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á", min_value=0, max_value=2,
                                                                        format="%.2f")
                },
                use_container_width=True
            )
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á")

        # --- REMOVED: PDF download section ---
        # The subheader and button for downloading the PDF have been removed from here.

    elif selected_analysis == "‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö AI Assistant":
        st.markdown("<h4 style='color: #001f3f;'>AI Assistant (‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI)</h4>", unsafe_allow_html=True)
        st.info(
            "‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô '‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏î‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏´‡∏±‡∏™ CPP101', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£'")

        AI_IS_CONFIGURED = False
        if genai:
            try:
                genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
                model = genai.GenerativeModel('gemini-1.5-flash')
                AI_IS_CONFIGURED = True
            except Exception as e:
                st.error(
                    f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ AI Assistant ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_API_KEY ‡πÉ‡∏ô secrets.toml ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß")
                st.caption(f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        else:
            st.error("‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ google-generativeai ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: pip install google-generativeai")

        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []

        chat_history_container = st.container(height=400, border=True)
        with chat_history_container:
            for message in st.session_state.chat_messages:
                avatar = LOGO_URL if message["role"] == "assistant" else "‚ùì"
                with st.chat_message(message["role"], avatar=avatar):
                    st.markdown(message["content"])

        if prompt := st.chat_input("‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á..."):
            st.session_state.chat_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user", avatar="‚ùì"):
                st.markdown(prompt)

            if AI_IS_CONFIGURED:
                with st.spinner("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                    df_for_ai = df_filtered.copy()
                    total_months_for_ai = total_month
                    prompt_lower = prompt.lower()
                    ai_prompt_for_gemini = ""
                    final_ai_response_text = ""

                    incident_code_match = re.search(r'[A-Z]{3}\d{3}', prompt.upper())

                    if incident_code_match:
                        extracted_code = incident_code_match.group(0)
                        incident_df = df_for_ai[df_for_ai['‡∏£‡∏´‡∏±‡∏™'] == extracted_code]
                        if incident_df.empty:
                            final_ai_response_text = f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏´‡∏±‡∏™ '{extracted_code}' ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            incident_name = incident_df['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].iloc[0]
                            total_count = len(incident_df)
                            severity_dist = incident_df['Impact'].value_counts().to_dict()
                            severity_text = ", ".join(
                                [f"‡∏£‡∏∞‡∏î‡∏±‡∏ö {k}: {v} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á" for k, v in severity_dist.items()]) or "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

                            poisson_df = calculate_frequency_trend_poisson(df_for_ai)
                            trend_row = poisson_df[poisson_df['‡∏£‡∏´‡∏±‡∏™'] == extracted_code]
                            trend_text = f"{trend_row['Poisson_Trend_Slope'].iloc[0]:.4f}" if not trend_row.empty else "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì"

                            persistence_df = calculate_persistence_risk_score(df_for_ai, total_months_for_ai)
                            persistence_row = persistence_df[persistence_df['‡∏£‡∏´‡∏±‡∏™'] == extracted_code]
                            persistence_text = f"{persistence_row['Persistence_Risk_Score'].iloc[0]:.2f}" if not persistence_row.empty else "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì"

                            ai_prompt_for_gemini = f"""
                                 ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏Ñ‡∏£‡∏±‡∏ö
                                 ‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏´‡∏±‡∏™ '{extracted_code}' ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
                                 - **‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå:** {incident_name}
                                 - **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ:** {total_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                                 - **‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á:** {severity_text}
                                 - **‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î (Poisson Trend Slope):** {trend_text} (‡∏Ñ‡πà‡∏≤‡∏ö‡∏ß‡∏Å = ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô, ‡∏Ñ‡πà‡∏≤‡∏•‡∏ö = ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏•‡∏î‡∏•‡∏á)
                                 - **‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (Persistence Score):** {persistence_text} (‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á)

                                 ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô **‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢** ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Markdown ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö
                                 """
                    elif '‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower or '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower:
                        severity_order = ['I', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A', '5', '4', '3', '2', '1']
                        df_sev = df_for_ai.copy()
                        df_sev['Impact_cat'] = pd.Categorical(df_sev['Impact'].astype(str), categories=severity_order,
                                                              ordered=True)
                        df_sorted = df_sev.sort_values(by=['Impact_cat', 'Occurrence Date'],
                                                       ascending=[True, False])

                        if df_sorted.empty or pd.isna(df_sorted['Impact_cat'].iloc[0]):
                            final_ai_response_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ ‡∏≠‡∏≤‡∏à‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            most_severe_incident = df_sorted.iloc[0]
                            incident_name = most_severe_incident.get('‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'N/A')
                            incident_code = most_severe_incident.get('‡∏£‡∏´‡∏±‡∏™', 'N/A')
                            impact_level = most_severe_incident.get('Impact', 'N/A')
                            occ_date = most_severe_incident.get('Occurrence Date').strftime(
                                '%d/%m/%Y') if pd.notna(
                                most_severe_incident.get('Occurrence Date')) else 'N/A'
                            details = most_severe_incident.get('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°')

                            final_ai_response_text = f"""‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠:
                             - **‡∏£‡∏´‡∏±‡∏™:** {incident_code}
                             - **‡∏ä‡∏∑‡πà‡∏≠:** {incident_name}
                             - **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á:** {impact_level}
                             - **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î):** {occ_date}
                             - **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:** {details}
                             """
                    elif ('‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô' in prompt_lower and ('‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower or '‡πÄ‡∏¢‡∏≠‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower)):
                        df_for_ai['MonthYear'] = df_for_ai['Occurrence Date'].dt.strftime('%B %Y')
                        monthly_counts = df_for_ai['MonthYear'].value_counts()

                        if monthly_counts.empty:
                            final_ai_response_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏î‡πâ"
                        else:
                            max_count = monthly_counts.iloc[0]
                            top_months = monthly_counts[monthly_counts == max_count]

                            if len(top_months) > 1:
                                months_str = ", ".join(top_months.index)
                                final_ai_response_text = f"‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {months_str} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞ {max_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
                            else:
                                max_month = monthly_counts.index[0]
                                final_ai_response_text = f"‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {max_month} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {max_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
                    elif ('‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô' in prompt_lower and '‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower):
                        current_year = datetime.now().year
                        if '‡∏õ‡∏µ‡∏ô‡∏µ‡πâ' in prompt_lower:
                            df_to_analyze = df_for_ai[df_for_ai['Occurrence Date'].dt.year == current_year].copy()
                            year_context = f"‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ {current_year} ‡∏ô‡∏µ‡πâ"
                        else:
                            df_to_analyze = df_for_ai.copy()
                            year_context = "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"

                        if df_to_analyze.empty:
                            final_ai_response_text = f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå{year_context.replace('‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö', ' ')}‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            df_to_analyze['MonthYear'] = df_to_analyze['Occurrence Date'].dt.strftime('%B %Y')
                            monthly_counts = df_to_analyze['MonthYear'].value_counts()

                            if monthly_counts.empty:
                                final_ai_response_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏î‡πâ"
                            else:
                                min_count = monthly_counts.iloc[-1]
                                bottom_months = monthly_counts[monthly_counts == min_count]

                                if len(bottom_months) > 1:
                                    months_str = ", ".join(bottom_months.index)
                                    final_ai_response_text = f"{year_context}, ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {months_str} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞ {min_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
                                else:
                                    min_month = monthly_counts.index[-1]
                                    final_ai_response_text = f"{year_context}, ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {min_month} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {min_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
                    elif '‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î' in prompt_lower or '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î' in prompt_lower:
                        most_frequent = df_freq.iloc[0]
                        incident_name = \
                            df_filtered[df_filtered['Incident'] == most_frequent['Incident']][
                                '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].iloc[0]
                        final_ai_response_text = f"‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠:\n- **‡∏£‡∏´‡∏±‡∏™:** {most_frequent['Incident']}\n- **‡∏ä‡∏∑‡πà‡∏≠:** {incident_name}\n- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô:** {most_frequent['count']} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
                    elif ('‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö' in prompt_lower or '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô' in prompt_lower) and (
                            '‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç' in prompt_lower) and ('safety goal' in prompt_lower or '‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢' in prompt_lower):

                        unresolved_conditions = df_for_ai['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
                        placeholders = ['N/A', 'N/A (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å AllCode ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)', 'N/A (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ô AllCode)']
                        df_goals = df_for_ai[~df_for_ai['‡∏´‡∏°‡∏ß‡∏î'].isin(placeholders)]

                        if df_goals.empty:
                            final_ai_response_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° Safety Goal ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            results = []
                            for category, group_df in df_goals.groupby('‡∏´‡∏°‡∏ß‡∏î'):
                                total_count = len(group_df)
                                unresolved_count = len(group_df[unresolved_conditions])
                                percentage = (unresolved_count / total_count * 100) if total_count > 0 else 0
                                results.append({
                                    '‡∏´‡∏°‡∏ß‡∏î': category,
                                    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç': percentage,
                                    '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î': f"({unresolved_count} ‡∏à‡∏≤‡∏Å {total_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"
                                })

                            if not results:
                                final_ai_response_text = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡∏≠‡∏á Safety Goals ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                            else:
                                sorted_results = sorted(results, key=lambda x: x['‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç'], reverse=True)
                                summary_list = [
                                    "‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Safety Goal ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö:"]
                                for res in sorted_results:
                                    summary_list.append(
                                        f"- **{res['‡∏´‡∏°‡∏ß‡∏î']}**: ‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç **{res['‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç']:.2f}%** {res['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î']}")
                                highest = sorted_results[0]
                                summary_list.append(
                                    f"\n**‡∏™‡∏£‡∏∏‡∏õ:** '{highest['‡∏´‡∏°‡∏ß‡∏î']}' ‡πÄ‡∏õ‡πá‡∏ô Safety Goal ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏á‡∏Ñ‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö")
                                final_ai_response_text = "\n".join(summary_list)
                    elif ('psg9' in prompt_lower and ('‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö' in prompt_lower or '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô' in prompt_lower) and (
                            '‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç' in prompt_lower or '‡∏Ñ‡πâ‡∏≤‡∏á' in prompt_lower)):

                        unresolved_conditions = df_for_ai['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
                        psg9_placeholders = ["‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)",
                                             "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î)"]
                        df_psg9 = df_for_ai[~df_for_ai['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].isin(psg9_placeholders)]

                        if df_psg9.empty:
                            final_ai_response_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PSG9 ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            results = []
                            for category, group_df in df_psg9.groupby('‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'):
                                total_count = len(group_df)
                                unresolved_count = len(group_df[unresolved_conditions])
                                percentage = (unresolved_count / total_count * 100) if total_count > 0 else 0
                                results.append({
                                    '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà': category,
                                    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç': percentage,
                                    '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î': f"({unresolved_count} ‡∏à‡∏≤‡∏Å {total_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"
                                })

                            if not results:
                                final_ai_response_text = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9 ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                            else:
                                sorted_results = sorted(results, key=lambda x: x['‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç'],
                                                        reverse=True)
                                summary_list = [
                                    "‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9 ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö:"]
                                for res in sorted_results:
                                    summary_list.append(
                                        f"- **{res['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà']}**: ‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç **{res['‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç']:.2f}%** {res['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î']}")
                                highest = sorted_results[0]
                                summary_list.append(
                                    f"\n**‡∏™‡∏£‡∏∏‡∏õ:** '{highest['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà']}' ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏á‡∏Ñ‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö")
                                final_ai_response_text = "\n".join(summary_list)
                    elif all(k in prompt_lower for k in ['‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô', '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà', '‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤']) and (
                            'c' in prompt_lower or 'g' in prompt_lower or '‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å' in prompt_lower or '‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ' in prompt_lower):

                        unresolved_conditions = df_for_ai['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
                        df_c = df_for_ai[df_for_ai['‡∏£‡∏´‡∏±‡∏™'].str.startswith('C', na=False)]
                        total_c = len(df_c)
                        unresolved_c = len(df_c[unresolved_conditions])
                        prop_c = (unresolved_c / total_c * 100) if total_c > 0 else 0
                        df_g = df_for_ai[df_for_ai['‡∏£‡∏´‡∏±‡∏™'].str.startswith('G', na=False)]
                        total_g = len(df_g)
                        unresolved_g = len(df_g[unresolved_conditions])
                        prop_g = (unresolved_g / total_g * 100) if total_g > 0 else 0

                        summary_text = (
                            f"‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö:\n\n"
                            f"- **‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å (C):**\n"
                            f"  - ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç {unresolved_c} ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_c} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n"
                            f"  - ‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô **{prop_c:.2f}%**\n\n"
                            f"- **‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (G):**\n"
                            f"  - ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç {unresolved_g} ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_g} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n"
                            f"  - ‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô **{prop_g:.2f}%**\n\n"
                        )

                        if prop_c > prop_g:
                            conclusion = f"**‡∏™‡∏£‡∏∏‡∏õ:** ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å (C) ‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö"
                        elif prop_g > prop_c:
                            conclusion = f"**‡∏™‡∏£‡∏∏‡∏õ:** ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (G) ‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            conclusion = f"**‡∏™‡∏£‡∏∏‡∏õ:** ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"

                        final_ai_response_text = summary_text + conclusion
                    elif 'sentinel' in prompt_lower:
                        sentinel_df = df_for_ai[df_for_ai['Sentinel code for check'].isin(sentinel_composite_keys)]
                        if sentinel_df.empty:
                            final_ai_response_text = "‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ, ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentinel Event ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
                        else:
                            sentinel_df['MonthYear'] = sentinel_df['Occurrence Date'].dt.strftime('%B %Y')
                            monthly_counts = sentinel_df['MonthYear'].value_counts()

                            if monthly_counts.empty:
                                final_ai_response_text = "‡∏û‡∏ö Sentinel Event ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                            else:
                                max_count = monthly_counts.iloc[0]
                                top_months = monthly_counts[monthly_counts == max_count]

                                if len(top_months) > 1:
                                    months_str = ", ".join(top_months.index)
                                    final_ai_response_text = f"‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ Sentinel Event ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {months_str} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞ {max_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
                                else:
                                    max_month = monthly_counts.index[0]
                                    final_ai_response_text = f"‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ Sentinel Event ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {max_month} ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {max_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
                    else:
                        summary_context = f"""
                             ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ:
                             - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {metrics_data.get('total_processed_incidents', 0)}
                             - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Sentinel Events: {metrics_data.get('total_sentinel_incidents_for_metric1', 0)}
                             - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5): {metrics_data.get('total_severe_incidents', 0)}
                             - ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {metrics_data.get('total_severe_unresolved_incidents_val', 'N/A')}
                             - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Top 5 ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î: {df_freq.head(5).to_string()}
                             """
                        ai_prompt_for_gemini = f"‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å:\n\n{summary_context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: '{prompt}'\n\n‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡∏£‡∏û‡∏ô‡∏≤‡∏°‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤ '‡∏ú‡∏°' ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ '‡∏Ñ‡∏£‡∏±‡∏ö'"

                    with st.chat_message("assistant", avatar=LOGO_URL):
                        final_response = ""
                        if final_ai_response_text:
                            final_response = final_ai_response_text
                            st.markdown(final_response)
                        elif ai_prompt_for_gemini:
                            try:
                                response = model.generate_content(ai_prompt_for_gemini)
                                final_response = response.text
                                st.markdown(final_response)
                            except Exception as e:
                                final_response = f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI: {e}"
                                st.error(final_response)
                        else:
                            final_response = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
                            st.markdown(final_response)

                    st.session_state.chat_messages.append({"role": "assistant", "content": final_response})


def main():
    page = st.query_params.get("page", "executive")
    if page == "admin":
        display_admin_page()
    else:
        display_executive_dashboard()


if __name__ == "__main__":
    main()
